# Phase 4: Integration Testing Framework

## Overview

Phase 4 creates a comprehensive integration testing framework that validates multi-component interactions within the LLMKG system. This phase ensures that components work correctly together, testing realistic workflows and complex scenarios that span multiple modules.

## Objectives

1. **Multi-Component Validation**: Test interactions between major system components
2. **Workflow Integration**: Validate complete data processing pipelines
3. **Interface Compatibility**: Ensure APIs and interfaces work correctly together
4. **Cross-Platform Testing**: Validate behavior across different deployment scenarios
5. **Real-World Scenario Testing**: Test realistic usage patterns and edge cases
6. **Performance Integration**: Verify performance characteristics in integrated scenarios

## Detailed Implementation Plan

### 1. Component Integration Testing

#### 1.1 Graph-Storage Integration Tests
**File**: `tests/integration/graph_storage_integration.rs`

```rust
mod graph_storage_integration {
    use super::*;
    use crate::test_infrastructure::*;
    use crate::synthetic_data::*;
    
    #[test]
    fn test_graph_csr_storage_integration() {
        let mut test_env = IntegrationTestEnvironment::new("graph_csr_integration");
        
        // Create test graph with known properties
        let graph_spec = GraphSpec {
            entity_count: 10000,
            relationship_count: 25000,
            topology: TopologyType::ScaleFree { exponent: 2.1 },
            clustering_coefficient: 0.3,
        };
        
        let test_graph = test_env.data_generator.generate_graph(&graph_spec);
        
        // Test 1: Graph construction and CSR conversion
        let mut kg = KnowledgeGraph::new();
        
        let construction_start = Instant::now();
        for entity in test_graph.entities {
            kg.add_entity(entity).expect("Failed to add entity");
        }
        
        for (source, target, relationship) in test_graph.relationships {
            kg.add_relationship(source, target, relationship)
                .expect("Failed to add relationship");
        }
        let construction_time = construction_start.elapsed();
        
        // Verify graph properties
        assert_eq!(kg.entity_count(), graph_spec.entity_count);
        assert_eq!(kg.relationship_count(), graph_spec.relationship_count);
        
        // Test 2: CSR storage format integrity
        let csr_storage = kg.get_csr_storage();
        
        // Verify CSR format properties
        let row_offsets = csr_storage.row_offsets();
        assert_eq!(row_offsets.len(), graph_spec.entity_count as usize + 1);
        
        let total_edges = row_offsets[row_offsets.len() - 1];
        assert_eq!(total_edges as u64, graph_spec.relationship_count);
        
        // Test 3: Query performance on CSR format
        let query_entities: Vec<EntityKey> = test_graph.entities.keys()
            .take(100)
            .cloned()
            .collect();
        
        let query_start = Instant::now();
        for &entity_key in &query_entities {
            let neighbors = kg.get_neighbors(entity_key);
            
            // Verify neighbors are reachable and valid
            for neighbor in neighbors {
                assert!(kg.contains_entity(neighbor.target()));
                assert!(neighbor.relationship().weight() > 0.0);
            }
        }
        let query_time = query_start.elapsed();
        
        // Performance validation
        let avg_query_time = query_time / query_entities.len() as u32;
        assert!(avg_query_time < Duration::from_micros(100),
               "Average query time too slow: {:?}", avg_query_time);
        
        println!("Graph construction: {:?}, Average query: {:?}", 
                construction_time, avg_query_time);
        
        test_env.record_performance("graph_construction_time", construction_time);
        test_env.record_performance("avg_query_time", avg_query_time);
    }
    
    #[test]
    fn test_graph_bloom_filter_integration() {
        let mut test_env = IntegrationTestEnvironment::new("graph_bloom_integration");
        
        // Create graph with predictable membership patterns
        let entity_count = 5000u64;
        let relationship_count = 12000u64;
        
        let test_data = test_env.data_generator.generate_membership_test_data(
            entity_count, relationship_count
        );
        
        let mut kg = KnowledgeGraph::new();
        
        // Build graph with bloom filter enabled
        kg.enable_bloom_filter(entity_count, 0.01).unwrap();
        
        for entity in test_data.entities {
            kg.add_entity(entity).unwrap();
        }
        
        for (source, target, rel) in test_data.relationships {
            kg.add_relationship(source, target, rel).unwrap();
        }
        
        // Test 1: Positive membership (should have no false negatives)
        for entity_key in test_data.known_entities.iter().take(1000) {
            let bloom_result = kg.bloom_filter_contains(entity_key);
            let actual_result = kg.contains_entity(*entity_key);
            
            assert_eq!(actual_result, true, "Test entity should exist in graph");
            assert_eq!(bloom_result, true, "Bloom filter false negative for {:?}", entity_key);
        }
        
        // Test 2: Negative membership (track false positives)
        let mut false_positives = 0;
        let test_count = 10000;
        
        for i in 0..test_count {
            let fake_entity = EntityKey::from_hash(format!("fake_entity_{}", i));
            let bloom_result = kg.bloom_filter_contains(&fake_entity);
            let actual_result = kg.contains_entity(fake_entity);
            
            assert_eq!(actual_result, false, "Fake entity should not exist");
            
            if bloom_result {
                false_positives += 1;
            }
        }
        
        let false_positive_rate = false_positives as f64 / test_count as f64;
        assert!(false_positive_rate <= 0.015, // Allow 50% margin over target
               "False positive rate too high: {} vs target 0.01", false_positive_rate);
        
        // Test 3: Performance impact of bloom filter
        let entities_to_query: Vec<EntityKey> = (0..1000)
            .map(|i| EntityKey::from_hash(format!("perf_test_{}", i)))
            .collect();
        
        // Time bloom filter checks
        let bloom_start = Instant::now();
        for entity in &entities_to_query {
            kg.bloom_filter_contains(entity);
        }
        let bloom_time = bloom_start.elapsed();
        
        // Time actual membership checks
        let membership_start = Instant::now();
        for entity in &entities_to_query {
            kg.contains_entity(*entity);
        }
        let membership_time = membership_start.elapsed();
        
        // Bloom filter should be significantly faster
        let speedup = membership_time.as_nanos() as f64 / bloom_time.as_nanos() as f64;
        assert!(speedup > 5.0, "Bloom filter should provide significant speedup: {}x", speedup);
        
        test_env.record_metric("false_positive_rate", false_positive_rate);
        test_env.record_metric("bloom_speedup", speedup);
    }
    
    #[test]
    fn test_graph_index_integration() {
        let mut test_env = IntegrationTestEnvironment::new("graph_index_integration");
        
        // Create graph with indexable attributes
        let graph_data = test_env.data_generator.generate_attributed_graph(
            2000, 5000, vec!["type", "category", "year", "score"]
        );
        
        let mut kg = KnowledgeGraph::new();
        
        // Build graph with indexing enabled
        kg.enable_attribute_indexing(vec!["type", "category", "year"]).unwrap();
        
        for entity in graph_data.entities {
            kg.add_entity(entity).unwrap();
        }
        
        for (source, target, rel) in graph_data.relationships {
            kg.add_relationship(source, target, rel).unwrap();
        }
        
        // Test 1: Attribute-based queries
        let type_values = vec!["paper", "author", "venue"];
        for type_value in type_values {
            let query_start = Instant::now();
            let entities = kg.find_entities_by_attribute("type", type_value);
            let query_time = query_start.elapsed();
            
            // Verify all results have the correct attribute
            for entity_key in &entities {
                let entity = kg.get_entity(*entity_key).unwrap();
                assert_eq!(entity.get_attribute("type"), Some(type_value));
            }
            
            // Performance should be sub-linear with total entity count
            assert!(query_time < Duration::from_millis(10),
                   "Attribute query too slow: {:?} for {} results", 
                   query_time, entities.len());
        }
        
        // Test 2: Range queries (for numeric attributes)
        let year_ranges = vec![(2000, 2010), (2010, 2020), (2020, 2025)];
        for (start_year, end_year) in year_ranges {
            let entities = kg.find_entities_by_attribute_range(
                "year", 
                &start_year.to_string(), 
                &end_year.to_string()
            );
            
            // Verify all results are in the correct range
            for entity_key in &entities {
                let entity = kg.get_entity(*entity_key).unwrap();
                if let Some(year_str) = entity.get_attribute("year") {
                    let year: i32 = year_str.parse().unwrap();
                    assert!(year >= start_year && year <= end_year,
                           "Entity year {} not in range [{}, {}]", year, start_year, end_year);
                }
            }
        }
        
        // Test 3: Compound queries
        let compound_results = kg.find_entities_by_multiple_attributes(vec![
            ("type", "paper"),
            ("category", "AI"),
        ]);
        
        // Verify all results match all criteria
        for entity_key in &compound_results {
            let entity = kg.get_entity(*entity_key).unwrap();
            assert_eq!(entity.get_attribute("type"), Some("paper"));
            assert_eq!(entity.get_attribute("category"), Some("AI"));
        }
        
        // Test 4: Index maintenance during updates
        let test_entity = graph_data.entities.keys().next().unwrap();
        let original_type = kg.get_entity(*test_entity).unwrap()
            .get_attribute("type").unwrap().to_string();
        
        // Update entity attribute
        kg.update_entity_attribute(*test_entity, "type", "updated_type").unwrap();
        
        // Verify old index entry is removed
        let old_results = kg.find_entities_by_attribute("type", &original_type);
        assert!(!old_results.contains(test_entity));
        
        // Verify new index entry is added
        let new_results = kg.find_entities_by_attribute("type", "updated_type");
        assert!(new_results.contains(test_entity));
    }
}
```

#### 1.2 Embedding-Graph Integration Tests
**File**: `tests/integration/embedding_graph_integration.rs`

```rust
mod embedding_graph_integration {
    use super::*;
    use crate::test_infrastructure::*;
    
    #[test]
    fn test_embedding_quantization_graph_rag_integration() {
        let mut test_env = IntegrationTestEnvironment::new("embedding_rag_integration");
        
        // Create test scenario with known structure
        let scenario = test_env.data_generator.generate_academic_scenario(
            1000, // papers
            300,  // authors  
            50,   // venues
            128   // embedding dimension
        );
        
        // Build knowledge graph
        let mut kg = KnowledgeGraph::new();
        for entity in scenario.entities {
            kg.add_entity(entity).unwrap();
        }
        for (source, target, rel) in scenario.relationships {
            kg.add_relationship(source, target, rel).unwrap();
        }
        
        // Set up embedding system with quantization
        let mut embedding_store = EmbeddingStore::new(128);
        let quantizer = ProductQuantizer::new(128, 256);
        
        // Train quantizer on embeddings
        let embeddings: Vec<Vec<f32>> = scenario.embeddings.values().cloned().collect();
        quantizer.train(&embeddings).unwrap();
        
        // Add quantized embeddings to store
        for (entity_key, embedding) in scenario.embeddings {
            let quantized = quantizer.quantize(&embedding);
            embedding_store.add_quantized_embedding(entity_key, quantized).unwrap();
        }
        
        // Test 1: RAG query with quantized embeddings
        let query_entity = scenario.central_entities[0];
        let rag_engine = GraphRagEngine::new(&kg, &embedding_store, &quantizer);
        
        let rag_start = Instant::now();
        let context = rag_engine.assemble_context(query_entity, &RagParameters {
            max_context_entities: 15,
            max_graph_depth: 2,
            similarity_threshold: 0.6,
            diversity_factor: 0.3,
        });
        let rag_time = rag_start.elapsed();
        
        // Verify context quality despite quantization
        assert_eq!(context.entities.len(), 15);
        assert!(context.entities.contains(&query_entity));
        
        // Compare with unquantized RAG for quality assessment
        let unquantized_store = EmbeddingStore::from_vectors(&scenario.embeddings);
        let unquantized_rag = GraphRagEngine::new(&kg, &unquantized_store, &NoQuantizer);
        let unquantized_context = unquantized_rag.assemble_context(query_entity, &RagParameters {
            max_context_entities: 15,
            max_graph_depth: 2, 
            similarity_threshold: 0.6,
            diversity_factor: 0.3,
        });
        
        // Quantized results should be similar to unquantized
        let context_overlap = calculate_entity_set_overlap(&context.entities, &unquantized_context.entities);
        assert!(context_overlap >= 0.7, 
               "Quantization degraded context quality: overlap {}", context_overlap);
        
        // Test 2: Similarity search accuracy with quantization
        let query_embedding = &scenario.embeddings[&query_entity];
        
        let quantized_results = embedding_store.similarity_search_quantized(query_embedding, 20);
        let unquantized_results = unquantized_store.similarity_search(query_embedding, 20);
        
        // Compare top-k results
        let similarity_overlap = calculate_ranked_overlap(&quantized_results, &unquantized_results, 10);
        assert!(similarity_overlap >= 0.8,
               "Quantization degraded similarity search: overlap {}", similarity_overlap);
        
        // Test 3: Memory efficiency validation  
        let quantized_memory = embedding_store.memory_usage();
        let unquantized_memory = unquantized_store.memory_usage();
        let compression_ratio = unquantized_memory as f64 / quantized_memory as f64;
        
        assert!(compression_ratio >= 10.0,
               "Insufficient compression ratio: {:.2}x", compression_ratio);
        
        // Test 4: Performance comparison
        assert!(rag_time < Duration::from_millis(100),
               "RAG with quantization too slow: {:?}", rag_time);
        
        test_env.record_metric("context_overlap", context_overlap);
        test_env.record_metric("similarity_overlap", similarity_overlap);
        test_env.record_metric("compression_ratio", compression_ratio);
        test_env.record_performance("rag_time", rag_time);
    }
    
    #[test]
    fn test_simd_embedding_integration() {
        let mut test_env = IntegrationTestEnvironment::new("simd_embedding_integration");
        
        // Create large-scale embedding scenario
        let entity_count = 10000;
        let embedding_dim = 256;
        let query_count = 100;
        
        let scenario = test_env.data_generator.generate_embedding_test_scenario(
            entity_count, embedding_dim, query_count
        );
        
        let mut embedding_store = EmbeddingStore::new(embedding_dim);
        
        // Add all embeddings
        for (entity_key, embedding) in scenario.embeddings {
            embedding_store.add_embedding(entity_key, embedding).unwrap();
        }
        
        // Test 1: SIMD vs scalar similarity search comparison
        for query_embedding in scenario.query_embeddings.iter().take(10) {
            // SIMD implementation
            let simd_start = Instant::now();
            let simd_results = embedding_store.similarity_search_simd(query_embedding, 50);
            let simd_time = simd_start.elapsed();
            
            // Scalar implementation (for validation)
            let scalar_start = Instant::now();
            let scalar_results = embedding_store.similarity_search_scalar(query_embedding, 50);
            let scalar_time = scalar_start.elapsed();
            
            // Results should be nearly identical
            assert_eq!(simd_results.len(), scalar_results.len());
            
            for (i, (simd_result, scalar_result)) in simd_results.iter().zip(scalar_results.iter()).enumerate() {
                assert_eq!(simd_result.entity, scalar_result.entity,
                          "Entity mismatch at position {}", i);
                
                let distance_diff = (simd_result.distance - scalar_result.distance).abs();
                assert!(distance_diff < 1e-4,
                       "Distance mismatch at position {}: {} vs {}", 
                       i, simd_result.distance, scalar_result.distance);
            }
            
            // SIMD should be significantly faster
            let speedup = scalar_time.as_nanos() as f64 / simd_time.as_nanos() as f64;
            assert!(speedup > 2.0, "SIMD speedup insufficient: {:.2}x", speedup);
        }
        
        // Test 2: Batch processing with SIMD
        let batch_start = Instant::now();
        let batch_results = embedding_store.batch_similarity_search_simd(
            &scenario.query_embeddings, 20
        );
        let batch_time = batch_start.elapsed();
        
        assert_eq!(batch_results.len(), scenario.query_embeddings.len());
        
        // Verify batch results match individual queries
        for (i, query_embedding) in scenario.query_embeddings.iter().enumerate() {
            let individual_results = embedding_store.similarity_search_simd(query_embedding, 20);
            let batch_result = &batch_results[i];
            
            assert_eq!(individual_results.len(), batch_result.len());
            
            for (individual, batch) in individual_results.iter().zip(batch_result.iter()) {
                assert_eq!(individual.entity, batch.entity);
                assert!((individual.distance - batch.distance).abs() < 1e-6);
            }
        }
        
        // Test 3: Memory access patterns with SIMD
        test_memory_access_patterns(&embedding_store, &scenario.query_embeddings);
        
        test_env.record_performance("batch_similarity_time", batch_time);
    }
    
    #[test]
    fn test_embedding_graph_consistency() {
        let mut test_env = IntegrationTestEnvironment::new("embedding_graph_consistency");
        
        // Create scenario where graph structure and embeddings are correlated
        let scenario = test_env.data_generator.generate_correlated_graph_embeddings(
            500, 1000, 128, 0.8 // 80% correlation between graph distance and embedding similarity
        );
        
        // Build systems
        let mut kg = KnowledgeGraph::new();
        for entity in scenario.entities {
            kg.add_entity(entity).unwrap();
        }
        for (source, target, rel) in scenario.relationships {
            kg.add_relationship(source, target, rel).unwrap();
        }
        
        let mut embedding_store = EmbeddingStore::new(128);
        for (entity_key, embedding) in scenario.embeddings {
            embedding_store.add_embedding(entity_key, embedding).unwrap();
        }
        
        // Test 1: Correlation between graph distance and embedding similarity
        let test_pairs = scenario.test_entity_pairs.iter().take(100);
        let mut correlation_data = Vec::new();
        
        for &(entity1, entity2) in test_pairs {
            // Graph distance
            let graph_distance = kg.shortest_path_length(entity1, entity2)
                .unwrap_or(u32::MAX) as f32;
            
            // Embedding similarity (convert to distance)
            let embedding1 = embedding_store.get_embedding(entity1).unwrap();
            let embedding2 = embedding_store.get_embedding(entity2).unwrap();
            let embedding_distance = euclidean_distance(&embedding1, &embedding2);
            
            correlation_data.push((graph_distance, embedding_distance));
        }
        
        let correlation = calculate_correlation(&correlation_data);
        assert!(correlation.abs() >= 0.5,  // Should be moderately correlated
               "Insufficient correlation between graph and embedding distances: {}", correlation);
        
        // Test 2: Consistency in neighborhood queries
        let test_entities = scenario.entities.keys().take(20);
        
        for &entity in test_entities {
            // Graph neighbors (1-hop)
            let graph_neighbors: HashSet<EntityKey> = kg.get_neighbors(entity)
                .into_iter()
                .map(|rel| rel.target())
                .collect();
            
            // Embedding neighbors (top-k similar)
            let embedding_neighbors: HashSet<EntityKey> = embedding_store
                .similarity_search(&embedding_store.get_embedding(entity).unwrap(), 20)
                .into_iter()
                .map(|result| result.entity)
                .collect();
            
            // Should have reasonable overlap
            let overlap = calculate_set_overlap_ratio(&graph_neighbors, &embedding_neighbors);
            if graph_neighbors.len() >= 5 {  // Only test for entities with enough neighbors
                assert!(overlap >= 0.2,
                       "Low overlap between graph and embedding neighbors: {}", overlap);
            }
        }
        
        test_env.record_metric("graph_embedding_correlation", correlation);
    }
}

fn test_memory_access_patterns(store: &EmbeddingStore, queries: &[Vec<f32>]) {
    // Test sequential vs random access patterns
    let entities: Vec<EntityKey> = store.get_all_entity_keys().collect();
    
    // Sequential access
    let sequential_start = Instant::now();
    for entity in entities.iter().take(1000) {
        let _embedding = store.get_embedding(*entity).unwrap();
    }
    let sequential_time = sequential_start.elapsed();
    
    // Random access
    let mut rng = rand::thread_rng();
    let random_indices: Vec<usize> = (0..1000)
        .map(|_| rng.gen_range(0..entities.len()))
        .collect();
    
    let random_start = Instant::now();
    for &idx in &random_indices {
        let _embedding = store.get_embedding(entities[idx]).unwrap();
    }
    let random_time = random_start.elapsed();
    
    // Sequential should be faster (cache-friendly)
    let ratio = random_time.as_nanos() as f64 / sequential_time.as_nanos() as f64;
    assert!(ratio > 1.1, "Memory access pattern not showing cache efficiency: ratio {}", ratio);
}
```

### 2. Cross-Platform Integration Testing

#### 2.1 WebAssembly Integration Tests
**File**: `tests/integration/wasm_integration.rs`

```rust
mod wasm_integration {
    use super::*;
    use wasm_bindgen_test::*;
    
    wasm_bindgen_test_configure!(run_in_browser);
    
    #[wasm_bindgen_test]
    fn test_wasm_knowledge_graph_basic_operations() {
        let mut kg = llmkg_wasm::KnowledgeGraph::new();
        
        // Test entity addition
        let entity_data = serde_json::json!({
            "key": "test_entity_1",
            "name": "Test Entity 1",
            "attributes": {
                "type": "test",
                "value": "42"
            }
        });
        
        let add_result = kg.add_entity_from_json(&entity_data.to_string());
        assert!(add_result.is_ok());
        
        // Test entity retrieval
        let retrieved = kg.get_entity_json("test_entity_1");
        assert!(retrieved.is_ok());
        
        let retrieved_data: serde_json::Value = serde_json::from_str(&retrieved.unwrap()).unwrap();
        assert_eq!(retrieved_data["name"], "Test Entity 1");
        assert_eq!(retrieved_data["attributes"]["type"], "test");
        
        // Test relationship addition
        kg.add_entity_from_json(&serde_json::json!({
            "key": "test_entity_2", 
            "name": "Test Entity 2",
            "attributes": {}
        }).to_string()).unwrap();
        
        let rel_result = kg.add_relationship_json(
            "test_entity_1",
            "test_entity_2", 
            &serde_json::json!({
                "name": "connects",
                "weight": 1.0,
                "type": "directed"
            }).to_string()
        );
        assert!(rel_result.is_ok());
        
        // Test graph statistics
        let stats = kg.get_statistics_json();
        let stats_data: serde_json::Value = serde_json::from_str(&stats).unwrap();
        assert_eq!(stats_data["entity_count"], 2);
        assert_eq!(stats_data["relationship_count"], 1);
    }
    
    #[wasm_bindgen_test]
    fn test_wasm_embedding_similarity_search() {
        let mut embedding_store = llmkg_wasm::EmbeddingStore::new(64);
        
        // Add test embeddings
        let test_entities = vec![
            ("entity_1", vec![1.0, 0.0, 0.0]),
            ("entity_2", vec![0.0, 1.0, 0.0]),
            ("entity_3", vec![0.0, 0.0, 1.0]),
            ("entity_4", vec![0.7, 0.7, 0.0]), // Similar to entity_1 and entity_2
        ];
        
        for (entity_id, mut embedding) in test_entities {
            embedding.resize(64, 0.0); // Pad to 64 dimensions
            let result = embedding_store.add_embedding_from_array(entity_id, &embedding);
            assert!(result.is_ok());
        }
        
        // Test similarity search
        let query_embedding = vec![1.0, 0.1, 0.0]; // Close to entity_1
        query_embedding.resize(64, 0.0);
        
        let results = embedding_store.similarity_search_from_array(&query_embedding, 3);
        assert!(results.is_ok());
        
        let results_json: serde_json::Value = serde_json::from_str(&results.unwrap()).unwrap();
        let results_array = results_json.as_array().unwrap();
        
        assert_eq!(results_array.len(), 3);
        
        // First result should be entity_1 (most similar)
        assert_eq!(results_array[0]["entity"], "entity_1");
        
        // Verify distances are sorted
        let dist1 = results_array[0]["distance"].as_f64().unwrap();
        let dist2 = results_array[1]["distance"].as_f64().unwrap();
        assert!(dist1 <= dist2);
    }
    
    #[wasm_bindgen_test]
    fn test_wasm_performance_measurement() {
        let mut kg = llmkg_wasm::KnowledgeGraph::new();
        let mut perf_monitor = llmkg_wasm::PerformanceMonitor::new();
        
        // Add entities with performance monitoring
        perf_monitor.start_measurement("entity_addition");
        
        for i in 0..1000 {
            let entity_data = serde_json::json!({
                "key": format!("entity_{}", i),
                "name": format!("Entity {}", i),
                "attributes": {"index": i.to_string()}
            });
            
            kg.add_entity_from_json(&entity_data.to_string()).unwrap();
        }
        
        let addition_time = perf_monitor.end_measurement("entity_addition");
        assert!(addition_time.is_ok());
        
        let time_ms = addition_time.unwrap();
        assert!(time_ms > 0.0);
        assert!(time_ms < 1000.0); // Should complete in under 1 second
        
        // Test query performance
        perf_monitor.start_measurement("entity_queries");
        
        for i in 0..100 {
            let entity_key = format!("entity_{}", i * 10);
            kg.get_entity_json(&entity_key).unwrap();
        }
        
        let query_time = perf_monitor.end_measurement("entity_queries").unwrap();
        let avg_query_time = query_time / 100.0;
        
        assert!(avg_query_time < 1.0); // Average query should be under 1ms
        
        // Test memory usage
        let memory_usage = kg.get_memory_usage_mb();
        assert!(memory_usage > 0.0);
        assert!(memory_usage < 50.0); // Should be reasonable for 1000 entities
    }
    
    #[wasm_bindgen_test]
    fn test_wasm_error_handling() {
        let mut kg = llmkg_wasm::KnowledgeGraph::new();
        
        // Test invalid JSON
        let invalid_json_result = kg.add_entity_from_json("invalid json{");
        assert!(invalid_json_result.is_err());
        
        // Test duplicate entity
        let entity_data = serde_json::json!({
            "key": "duplicate_test",
            "name": "Duplicate Test",
            "attributes": {}
        });
        
        kg.add_entity_from_json(&entity_data.to_string()).unwrap();
        let duplicate_result = kg.add_entity_from_json(&entity_data.to_string());
        assert!(duplicate_result.is_err());
        
        // Test nonexistent entity retrieval
        let nonexistent_result = kg.get_entity_json("nonexistent_entity");
        assert!(nonexistent_result.is_err());
        
        // Test invalid relationship
        let invalid_rel_result = kg.add_relationship_json(
            "nonexistent_source",
            "nonexistent_target",
            &serde_json::json!({"name": "test", "weight": 1.0}).to_string()
        );
        assert!(invalid_rel_result.is_err());
    }
}
```

#### 2.2 MCP Integration Tests
**File**: `tests/integration/mcp_integration.rs`

```rust
mod mcp_integration {
    use super::*;
    use crate::test_infrastructure::*;
    use tokio_test;
    
    #[tokio::test]
    async fn test_mcp_server_tool_integration() {
        let mut test_env = IntegrationTestEnvironment::new("mcp_integration");
        
        // Set up test knowledge graph
        let scenario = test_env.data_generator.generate_academic_scenario(200, 100, 20, 128);
        
        let mut kg = KnowledgeGraph::new();
        for entity in scenario.entities {
            kg.add_entity(entity).unwrap();
        }
        for (source, target, rel) in scenario.relationships {
            kg.add_relationship(source, target, rel).unwrap();
        }
        
        let mut embedding_store = EmbeddingStore::new(128);
        for (entity_key, embedding) in scenario.embeddings {
            embedding_store.add_embedding(entity_key, embedding).unwrap();
        }
        
        // Create MCP server
        let mcp_server = LlmFriendlyServer::new(kg, embedding_store);
        
        // Test 1: knowledge_search tool
        let search_request = McpToolRequest {
            tool_name: "knowledge_search".to_string(),
            arguments: serde_json::json!({
                "query": "machine learning algorithms",
                "max_results": 10,
                "include_context": true
            }),
        };
        
        let search_response = mcp_server.handle_tool_request(search_request).await;
        assert!(search_response.is_ok());
        
        let search_result = search_response.unwrap();
        assert_eq!(search_result.tool_name, "knowledge_search");
        assert!(search_result.success);
        
        let result_data: serde_json::Value = serde_json::from_str(&search_result.content).unwrap();
        let results = result_data["results"].as_array().unwrap();
        
        assert!(results.len() <= 10);
        assert!(!results.is_empty());
        
        // Verify result structure
        for result in results {
            assert!(result["entity"].is_string());
            assert!(result["relevance_score"].is_number());
            assert!(result["context"].is_array());
        }
        
        // Test 2: entity_lookup tool
        let lookup_request = McpToolRequest {
            tool_name: "entity_lookup".to_string(),
            arguments: serde_json::json!({
                "entity_key": scenario.central_entities[0].to_string(),
                "include_relationships": true,
                "max_relationships": 5
            }),
        };
        
        let lookup_response = mcp_server.handle_tool_request(lookup_request).await;
        assert!(lookup_response.is_ok());
        
        let lookup_result = lookup_response.unwrap();
        assert!(lookup_result.success);
        
        let lookup_data: serde_json::Value = serde_json::from_str(&lookup_result.content).unwrap();
        assert!(lookup_data["entity"].is_object());
        assert!(lookup_data["relationships"].is_array());
        
        // Test 3: find_connections tool
        let connection_request = McpToolRequest {
            tool_name: "find_connections".to_string(),
            arguments: serde_json::json!({
                "source_entity": scenario.central_entities[0].to_string(),
                "target_entity": scenario.central_entities[1].to_string(),
                "max_path_length": 3,
                "max_paths": 5
            }),
        };
        
        let connection_response = mcp_server.handle_tool_request(connection_request).await;
        assert!(connection_response.is_ok());
        
        let connection_result = connection_response.unwrap();
        if connection_result.success {
            let connection_data: serde_json::Value = serde_json::from_str(&connection_result.content).unwrap();
            let paths = connection_data["paths"].as_array().unwrap();
            
            for path in paths {
                let entities = path["entities"].as_array().unwrap();
                assert!(entities.len() >= 2);
                assert!(entities.len() <= 4); // max_path_length + 1
            }
        }
        
        // Test 4: Error handling
        let invalid_request = McpToolRequest {
            tool_name: "nonexistent_tool".to_string(),
            arguments: serde_json::json!({}),
        };
        
        let error_response = mcp_server.handle_tool_request(invalid_request).await;
        assert!(error_response.is_ok());
        
        let error_result = error_response.unwrap();
        assert!(!error_result.success);
        assert!(error_result.error_message.is_some());
    }
    
    #[tokio::test]
    async fn test_mcp_federated_server() {
        let mut test_env = IntegrationTestEnvironment::new("mcp_federated");
        
        // Create federated setup
        let federation_data = test_env.data_generator.generate_federation_scenario(3, 1000);
        
        let mut databases = Vec::new();
        for (i, shard) in federation_data.shards.iter().enumerate() {
            let mut kg = KnowledgeGraph::new();
            
            for entity_key in &shard.entities {
                let entity = Entity::new(*entity_key, format!("Entity {}", entity_key));
                kg.add_entity(entity).unwrap();
            }
            
            for relationship in &shard.relationships {
                kg.add_relationship(
                    relationship.source,
                    relationship.target,
                    relationship.relationship.clone()
                ).unwrap();
            }
            
            databases.push((format!("db_{}", i), kg));
        }
        
        let federated_server = FederatedServer::new(databases);
        
        // Test 1: Cross-database query
        let cross_db_request = McpToolRequest {
            tool_name: "federated_search".to_string(),
            arguments: serde_json::json!({
                "query": "distributed entity search",
                "max_results_per_db": 5,
                "merge_strategy": "union"
            }),
        };
        
        let federated_response = federated_server.handle_tool_request(cross_db_request).await;
        assert!(federated_response.is_ok());
        
        let federated_result = federated_response.unwrap();
        assert!(federated_result.success);
        
        let result_data: serde_json::Value = serde_json::from_str(&federated_result.content).unwrap();
        let databases_results = result_data["database_results"].as_object().unwrap();
        
        assert_eq!(databases_results.len(), 3); // Should query all 3 databases
        
        // Test 2: Database-specific query
        let specific_db_request = McpToolRequest {
            tool_name: "database_query".to_string(),
            arguments: serde_json::json!({
                "database_id": "db_0",
                "query_type": "entity_count"
            }),
        };
        
        let specific_response = federated_server.handle_tool_request(specific_db_request).await;
        assert!(specific_response.is_ok());
        
        let specific_result = specific_response.unwrap();
        assert!(specific_result.success);
        
        // Test 3: Federation statistics
        let stats_request = McpToolRequest {
            tool_name: "federation_stats".to_string(),
            arguments: serde_json::json!({}),
        };
        
        let stats_response = federated_server.handle_tool_request(stats_request).await;
        assert!(stats_response.is_ok());
        
        let stats_result = stats_response.unwrap();
        assert!(stats_result.success);
        
        let stats_data: serde_json::Value = serde_json::from_str(&stats_result.content).unwrap();
        assert!(stats_data["total_databases"].is_number());
        assert!(stats_data["total_entities"].is_number());
        assert!(stats_data["total_relationships"].is_number());
    }
    
    #[tokio::test]
    async fn test_mcp_performance_monitoring() {
        let mut test_env = IntegrationTestEnvironment::new("mcp_performance");
        
        // Set up medium-scale test
        let scenario = test_env.data_generator.generate_performance_test_scenario(1000, 2000);
        
        let mut kg = KnowledgeGraph::new();
        for entity in scenario.entities {
            kg.add_entity(entity).unwrap();
        }
        for (source, target, rel) in scenario.relationships {
            kg.add_relationship(source, target, rel).unwrap();
        }
        
        let mcp_server = LlmFriendlyServer::new(kg, EmbeddingStore::new(128));
        
        // Test concurrent requests
        let mut request_futures = Vec::new();
        
        for i in 0..50 {
            let server_clone = mcp_server.clone();
            let request = McpToolRequest {
                tool_name: "knowledge_search".to_string(),
                arguments: serde_json::json!({
                    "query": format!("test query {}", i),
                    "max_results": 5
                }),
            };
            
            let future = async move {
                let start_time = Instant::now();
                let response = server_clone.handle_tool_request(request).await;
                let elapsed = start_time.elapsed();
                (response, elapsed)
            };
            
            request_futures.push(future);
        }
        
        // Execute all requests concurrently
        let results = futures::future::join_all(request_futures).await;
        
        // Verify all succeeded and measure performance
        let mut total_time = Duration::from_nanos(0);
        let mut success_count = 0;
        
        for (response, elapsed) in results {
            assert!(response.is_ok());
            let result = response.unwrap();
            if result.success {
                success_count += 1;
                total_time += elapsed;
                
                // Individual requests should be fast
                assert!(elapsed < Duration::from_millis(100),
                       "Individual request too slow: {:?}", elapsed);
            }
        }
        
        assert_eq!(success_count, 50);
        
        let avg_time = total_time / 50;
        assert!(avg_time < Duration::from_millis(50),
               "Average request time too slow: {:?}", avg_time);
        
        test_env.record_performance("avg_mcp_request_time", avg_time);
        test_env.record_metric("mcp_success_rate", success_count as f64 / 50.0);
    }
}
```

### 3. Performance Integration Testing

#### 3.1 End-to-End Performance Tests
**File**: `tests/integration/performance_integration.rs`

```rust
mod performance_integration {
    use super::*;
    use crate::test_infrastructure::*;
    
    #[test]
    fn test_query_latency_integration() {
        let mut test_env = IntegrationTestEnvironment::new("query_latency");
        
        // Test different graph sizes
        let sizes = vec![1000, 5000, 10000, 25000];
        
        for &size in &sizes {
            println!("Testing query latency for {} entities", size);
            
            // Generate test graph
            let scenario = test_env.data_generator.generate_performance_graph(
                size, size * 2, 128
            );
            
            // Build complete system
            let mut kg = KnowledgeGraph::new();
            for entity in scenario.entities {
                kg.add_entity(entity).unwrap();
            }
            for (source, target, rel) in scenario.relationships {
                kg.add_relationship(source, target, rel).unwrap();
            }
            
            let mut embedding_store = EmbeddingStore::new(128);
            for (entity_key, embedding) in scenario.embeddings {
                embedding_store.add_embedding(entity_key, embedding).unwrap();
            }
            
            let rag_engine = GraphRagEngine::new(&kg, &embedding_store);
            
            // Test 1: Single-hop queries
            let test_entities: Vec<EntityKey> = kg.get_all_entities()
                .take(100)
                .map(|e| e.key())
                .collect();
            
            let mut single_hop_times = Vec::new();
            for &entity in &test_entities {
                let start = Instant::now();
                let _neighbors = kg.get_neighbors(entity);
                let elapsed = start.elapsed();
                single_hop_times.push(elapsed);
            }
            
            let avg_single_hop = single_hop_times.iter().sum::<Duration>() / single_hop_times.len() as u32;
            
            // Target: < 1ms for single-hop queries
            assert!(avg_single_hop < Duration::from_millis(1),
                   "Single-hop queries too slow for size {}: {:?}", size, avg_single_hop);
            
            // Test 2: Multi-hop traversal
            let mut multi_hop_times = Vec::new();
            for &entity in test_entities.iter().take(20) {
                let start = Instant::now();
                let _traversal = kg.breadth_first_search(entity, 3);
                let elapsed = start.elapsed();
                multi_hop_times.push(elapsed);
            }
            
            let avg_multi_hop = multi_hop_times.iter().sum::<Duration>() / multi_hop_times.len() as u32;
            
            // Should scale reasonably with depth
            assert!(avg_multi_hop < Duration::from_millis(10),
                   "Multi-hop queries too slow for size {}: {:?}", size, avg_multi_hop);
            
            // Test 3: Similarity search
            let query_embedding = vec![0.1; 128];
            let mut similarity_times = Vec::new();
            
            for _ in 0..50 {
                let start = Instant::now();
                let _results = embedding_store.similarity_search(&query_embedding, 20);
                let elapsed = start.elapsed();
                similarity_times.push(elapsed);
            }
            
            let avg_similarity = similarity_times.iter().sum::<Duration>() / similarity_times.len() as u32;
            
            // Target: < 5ms for similarity search
            assert!(avg_similarity < Duration::from_millis(5),
                   "Similarity search too slow for size {}: {:?}", size, avg_similarity);
            
            // Test 4: RAG context assembly
            let mut rag_times = Vec::new();
            for &entity in test_entities.iter().take(10) {
                let start = Instant::now();
                let _context = rag_engine.assemble_context(entity, &RagParameters::default());
                let elapsed = start.elapsed();
                rag_times.push(elapsed);
            }
            
            let avg_rag = rag_times.iter().sum::<Duration>() / rag_times.len() as u32;
            
            // Should be reasonable for complex operation
            assert!(avg_rag < Duration::from_millis(50),
                   "RAG assembly too slow for size {}: {:?}", size, avg_rag);
            
            // Record metrics
            test_env.record_performance_for_size(size, "single_hop_avg", avg_single_hop);
            test_env.record_performance_for_size(size, "multi_hop_avg", avg_multi_hop);
            test_env.record_performance_for_size(size, "similarity_avg", avg_similarity);
            test_env.record_performance_for_size(size, "rag_avg", avg_rag);
        }
        
        // Analyze scaling behavior
        test_env.analyze_scaling_behavior(&["single_hop_avg", "similarity_avg"]);
    }
    
    #[test]
    fn test_memory_efficiency_integration() {
        let mut test_env = IntegrationTestEnvironment::new("memory_efficiency");
        
        let sizes = vec![1000, 5000, 10000];
        
        for &size in &sizes {
            // Create test scenario
            let scenario = test_env.data_generator.generate_memory_test_scenario(size);
            
            // Measure baseline memory
            let baseline_memory = get_current_memory_usage();
            
            // Build knowledge graph
            let mut kg = KnowledgeGraph::new();
            for entity in scenario.entities {
                kg.add_entity(entity).unwrap();
            }
            
            let graph_memory = get_current_memory_usage();
            let graph_overhead = graph_memory - baseline_memory;
            
            // Add relationships
            for (source, target, rel) in scenario.relationships {
                kg.add_relationship(source, target, rel).unwrap();
            }
            
            let relationships_memory = get_current_memory_usage();
            let relationships_overhead = relationships_memory - graph_memory;
            
            // Add embeddings
            let mut embedding_store = EmbeddingStore::new(128);
            for (entity_key, embedding) in scenario.embeddings {
                embedding_store.add_embedding(entity_key, embedding).unwrap();
            }
            
            let embeddings_memory = get_current_memory_usage();
            let embeddings_overhead = embeddings_memory - relationships_memory;
            
            // Calculate memory per entity
            let memory_per_entity = (embeddings_memory - baseline_memory) / size as u64;
            
            println!("Size {}: {} bytes per entity", size, memory_per_entity);
            
            // Target: < 70 bytes per entity total
            assert!(memory_per_entity < 70,
                   "Memory per entity too high for size {}: {} bytes", size, memory_per_entity);
            
            // Verify memory efficiency of components
            let graph_per_entity = graph_overhead / size as u64;
            let relationships_per_rel = relationships_overhead / scenario.relationship_count;
            let embeddings_per_entity = embeddings_overhead / size as u64;
            
            assert!(graph_per_entity < 30, "Graph overhead too high: {} bytes/entity", graph_per_entity);
            assert!(relationships_per_rel < 20, "Relationship overhead too high: {} bytes/rel", relationships_per_rel);
            // Embeddings can be larger due to vector storage
            
            test_env.record_memory_usage(size, "total_per_entity", memory_per_entity);
            test_env.record_memory_usage(size, "graph_per_entity", graph_per_entity);
            test_env.record_memory_usage(size, "embeddings_per_entity", embeddings_per_entity);
        }
    }
    
    #[test]
    fn test_compression_integration() {
        let mut test_env = IntegrationTestEnvironment::new("compression_integration");
        
        // Test vector quantization compression
        let embedding_sizes = vec![1000, 5000, 10000];
        let dimensions = vec![64, 128, 256];
        
        for &size in &embedding_sizes {
            for &dim in &dimensions {
                let embeddings = test_env.data_generator.generate_random_embeddings(size, dim);
                
                // Measure uncompressed size
                let uncompressed_size = size * dim * std::mem::size_of::<f32>();
                
                // Train quantizer and compress
                let mut quantizer = ProductQuantizer::new(dim, 256);
                let embedding_vectors: Vec<Vec<f32>> = embeddings.values().cloned().collect();
                quantizer.train(&embedding_vectors).unwrap();
                
                // Measure compressed size
                let mut compressed_size = quantizer.memory_usage();
                for embedding in &embedding_vectors {
                    let quantized = quantizer.quantize(embedding);
                    compressed_size += quantized.len() * std::mem::size_of::<u8>();
                }
                
                let compression_ratio = uncompressed_size as f64 / compressed_size as f64;
                
                println!("Size {}, Dim {}: {:.1}x compression", size, dim, compression_ratio);
                
                // Target: > 10x compression
                assert!(compression_ratio >= 10.0,
                       "Insufficient compression for size {} dim {}: {:.1}x", 
                       size, dim, compression_ratio);
                
                // Test reconstruction accuracy
                let mut total_error = 0.0;
                for (i, embedding) in embedding_vectors.iter().take(100).enumerate() {
                    let quantized = quantizer.quantize(embedding);
                    let reconstructed = quantizer.reconstruct(&quantized);
                    
                    let error = euclidean_distance(embedding, &reconstructed);
                    total_error += error;
                }
                
                let avg_error = total_error / 100.0;
                
                // Reconstruction should be reasonably accurate
                assert!(avg_error < 2.0, "Reconstruction error too high: {}", avg_error);
                
                test_env.record_compression_ratio(size, dim, compression_ratio);
                test_env.record_reconstruction_error(size, dim, avg_error);
            }
        }
    }
    
    #[test]
    fn test_concurrent_access_integration() {
        let mut test_env = IntegrationTestEnvironment::new("concurrent_access");
        
        // Create shared knowledge graph
        let scenario = test_env.data_generator.generate_concurrent_test_scenario(5000, 10000);
        
        let kg = Arc::new(RwLock::new(KnowledgeGraph::new()));
        
        // Populate graph
        {
            let mut kg_write = kg.write().unwrap();
            for entity in scenario.entities {
                kg_write.add_entity(entity).unwrap();
            }
            for (source, target, rel) in scenario.relationships {
                kg_write.add_relationship(source, target, rel).unwrap();
            }
        }
        
        let embedding_store = Arc::new(RwLock::new(EmbeddingStore::new(128)));
        
        // Populate embeddings
        {
            let mut store_write = embedding_store.write().unwrap();
            for (entity_key, embedding) in scenario.embeddings {
                store_write.add_embedding(entity_key, embedding).unwrap();
            }
        }
        
        // Test concurrent readers
        let reader_count = 10;
        let queries_per_reader = 100;
        
        let mut reader_handles = Vec::new();
        
        for reader_id in 0..reader_count {
            let kg_clone = Arc::clone(&kg);
            let store_clone = Arc::clone(&embedding_store);
            let test_entities = scenario.test_entities.clone();
            
            let handle = thread::spawn(move || {
                let mut query_times = Vec::new();
                
                for i in 0..queries_per_reader {
                    let entity = test_entities[i % test_entities.len()];
                    
                    let start = Instant::now();
                    
                    // Read from graph
                    {
                        let kg_read = kg_clone.read().unwrap();
                        let _neighbors = kg_read.get_neighbors(entity);
                    }
                    
                    // Read from embeddings
                    {
                        let store_read = store_clone.read().unwrap();
                        if let Ok(embedding) = store_read.get_embedding(entity) {
                            let _results = store_read.similarity_search(&embedding, 10);
                        }
                    }
                    
                    let elapsed = start.elapsed();
                    query_times.push(elapsed);
                }
                
                (reader_id, query_times)
            });
            
            reader_handles.push(handle);
        }
        
        // Wait for all readers to complete
        let mut all_times = Vec::new();
        for handle in reader_handles {
            let (reader_id, times) = handle.join().unwrap();
            all_times.extend(times);
            
            let avg_time = times.iter().sum::<Duration>() / times.len() as u32;
            println!("Reader {}: avg time {:?}", reader_id, avg_time);
            
            // Each reader should maintain good performance
            assert!(avg_time < Duration::from_millis(2),
                   "Reader {} too slow: {:?}", reader_id, avg_time);
        }
        
        // Overall performance should be reasonable
        let overall_avg = all_times.iter().sum::<Duration>() / all_times.len() as u32;
        assert!(overall_avg < Duration::from_millis(2),
               "Overall concurrent performance too slow: {:?}", overall_avg);
        
        test_env.record_performance("concurrent_avg_time", overall_avg);
        test_env.record_metric("concurrent_reader_count", reader_count as f64);
    }
}

fn get_current_memory_usage() -> u64 {
    // Platform-specific memory measurement
    #[cfg(target_os = "linux")]
    {
        use std::fs;
        let status = fs::read_to_string("/proc/self/status").unwrap();
        for line in status.lines() {
            if line.starts_with("VmRSS:") {
                let parts: Vec<&str> = line.split_whitespace().collect();
                if parts.len() >= 2 {
                    return parts[1].parse::<u64>().unwrap() * 1024; // Convert KB to bytes
                }
            }
        }
    }
    
    #[cfg(target_os = "windows")]
    {
        use winapi::um::processthreadsapi::GetCurrentProcess;
        use winapi::um::psapi::{GetProcessMemoryInfo, PROCESS_MEMORY_COUNTERS};
        use std::mem;
        
        unsafe {
            let mut pmc: PROCESS_MEMORY_COUNTERS = mem::zeroed();
            let result = GetProcessMemoryInfo(
                GetCurrentProcess(),
                &mut pmc as *mut _,
                mem::size_of::<PROCESS_MEMORY_COUNTERS>() as u32,
            );
            
            if result != 0 {
                return pmc.WorkingSetSize as u64;
            }
        }
    }
    
    // Fallback for other platforms or if measurement fails
    0
}
```

## Implementation Strategy

### Week 1: Core Integration Tests
**Days 1-2**: Graph-storage integration and bloom filter tests
**Days 3-4**: Embedding-graph integration and RAG tests
**Days 5**: Cross-platform integration (WASM, native)

### Week 2: Advanced Integration Tests
**Days 6-7**: MCP integration and federation tests  
**Days 8-9**: Performance integration and scaling tests
**Days 10**: Concurrent access and stress integration tests

## Test Environment Management

### Containerized Testing
```dockerfile
# Integration test environment
FROM rust:1.70

# Install testing dependencies
RUN apt-get update && apt-get install -y \
    nodejs npm \
    python3 python3-pip \
    wasm-pack \
    && rm -rf /var/lib/apt/lists/*

# Install WASM testing tools
RUN cargo install wasm-bindgen-cli
RUN npm install -g @web/test-runner

# Set up test workspace
WORKDIR /tests
COPY . .

# Run integration tests
CMD ["cargo", "test", "--release", "--package", "llmkg-integration-tests"]
```

### CI/CD Integration
```yaml
name: Integration Tests

on: [push, pull_request]

jobs:
  integration-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        platform: [linux, windows, macos]
        features: [default, wasm, mcp, federation]
    
    steps:
      - uses: actions/checkout@v3
      - name: Setup Rust
        uses: actions-rs/toolchain@v1
        with:
          toolchain: stable
          
      - name: Run Integration Tests
        run: |
          cargo test --release \
            --package llmkg-integration-tests \
            --features ${{ matrix.features }}
            
      - name: Upload Test Results
        uses: actions/upload-artifact@v3
        with:
          name: integration-test-results-${{ matrix.platform }}-${{ matrix.features }}
          path: target/test-results/
```

## Success Criteria

### Functional Requirements
-  All component integrations work correctly
-  Cross-platform compatibility verified
-  MCP tools function properly in integration
-  Performance targets met in integrated scenarios

### Quality Requirements  
-  Integration tests cover all major workflows
-  Error handling works across component boundaries
-  Resource management is proper in integrated scenarios
-  Concurrent access patterns are safe and performant

### Performance Requirements
-  Integration test suite completes in <30 minutes
-  Performance degradation in integration is minimal (<10%)
-  Memory usage remains bounded in integrated scenarios
-  Scaling behavior is predictable across integration points

This comprehensive integration testing framework validates that all LLMKG components work correctly together, ensuring the system performs as expected in real-world scenarios across different platforms and deployment configurations.