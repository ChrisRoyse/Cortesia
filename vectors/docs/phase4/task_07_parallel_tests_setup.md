# Task 07: Create Parallel Tests Setup

## Context
You are implementing Phase 4 of a vector indexing system. Now you need to create comprehensive test infrastructure for parallel indexing, including performance comparison tests and edge case validation.

## Current State
- `src/parallel.rs` exists with complete `ParallelIndexer` implementation
- Directory indexing and file filtering are working
- Basic tests exist but need expansion for parallel-specific scenarios

## Task Objective
Set up comprehensive test infrastructure with test data generation, performance benchmarks, and parallel-specific validation tests.

## Implementation Requirements

### 1. Add test dependencies
Ensure these are in your `Cargo.toml` `[dev-dependencies]`:
```toml
tempfile = "3.8"
criterion = "0.5" # For benchmarking if needed
```

### 2. Create test data generation helpers
Add these helper functions to the test module in `src/parallel.rs`:
```rust
#[cfg(test)]
mod tests {
    use super::*;
    use tempfile::TempDir;
    use std::fs;\n    \n    // Helper to create test project structure\n    fn create_test_project(base_dir: &Path, num_files: usize) -> Result<Vec<PathBuf>> {\n        let mut created_files = Vec::new();\n        \n        // Create src directory with Rust files\n        let src_dir = base_dir.join(\"src\");\n        std::fs::create_dir_all(&src_dir)?;\n        \n        for i in 0..num_files {\n            let file_path = src_dir.join(format!(\"module_{}.rs\", i));\n            let content = format!(\n                \"pub struct Data{} {{\\n    value: i32,\\n    name: String,\\n}}\\n\\npub fn process_{}() -> Result<Data{}, Error> {{\\n    Ok(Data{} {{\\n        value: {},\\n        name: \\\"item_{}\\\".to_string(),\\n    }})\\n}}\", \n                i, i, i, i, i, i\n            );\n            std::fs::write(&file_path, content)?;\n            created_files.push(file_path);\n        }\n        \n        // Create docs directory with markdown files\n        let docs_dir = base_dir.join(\"docs\");\n        std::fs::create_dir_all(&docs_dir)?;\n        \n        for i in 0..(num_files / 2) {\n            let file_path = docs_dir.join(format!(\"doc_{}.md\", i));\n            let content = format!(\"# Documentation {}\\n\\nThis is documentation for module {}.\", i, i);\n            std::fs::write(&file_path, content)?;\n            created_files.push(file_path);\n        }\n        \n        // Create config files\n        std::fs::write(base_dir.join(\"Cargo.toml\"), \"[package]\\nname = \\\"test\\\"\\nversion = \\\"0.1.0\\\"\")?;\n        std::fs::write(base_dir.join(\"README.md\"), \"# Test Project\\n\\nThis is a test project.\")?;\n        created_files.push(base_dir.join(\"Cargo.toml\"));\n        created_files.push(base_dir.join(\"README.md\"));\n        \n        // Create non-indexable files\n        let target_dir = base_dir.join(\"target\");\n        std::fs::create_dir_all(&target_dir)?;\n        std::fs::write(target_dir.join(\"binary.exe\"), \"binary data\")?;\n        \n        let git_dir = base_dir.join(\".git\");\n        std::fs::create_dir_all(&git_dir)?;\n        std::fs::write(git_dir.join(\"config\"), \"git config\")?;\n        \n        Ok(created_files)\n    }\n    \n    // Helper to measure execution time\n    fn time_execution<F, R>(f: F) -> (R, std::time::Duration)\n    where\n        F: FnOnce() -> R,\n    {\n        let start = std::time::Instant::now();\n        let result = f();\n        let duration = start.elapsed();\n        (result, duration)\n    }\n    \n    // ... existing tests ...\n}\n```\n\n### 3. Add large-scale parallel test\nAdd this test to validate parallel processing with many files:\n```rust\n#[test]\nfn test_parallel_indexing_large_scale() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let index_path = temp_dir.path().join(\"index\");\n    let parallel_indexer = ParallelIndexer::new(&index_path)?;\n    \n    // Create 100 test files\n    let test_project = temp_dir.path().join(\"large_project\");\n    let created_files = create_test_project(&test_project, 100)?;\n    \n    // Index in parallel\n    let (stats, duration) = time_execution(|| {\n        parallel_indexer.index_directory_parallel(&test_project)\n    });\n    let stats = stats?;\n    \n    // Validate results\n    assert!(stats.files_processed >= 100); // At least the files we created\n    assert!(stats.total_size > 0);\n    assert!(duration.as_millis() < 30000); // Should complete in reasonable time\n    \n    println!(\"Large scale test: {}\", stats.summary());\n    println!(\"Duration: {:?}\", duration);\n    \n    Ok(())\n}\n```\n\n### 4. Add thread safety test\nAdd this test to validate thread safety:\n```rust\n#[test]\nfn test_parallel_thread_safety() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let index_path = temp_dir.path().join(\"index\");\n    let parallel_indexer = Arc::new(ParallelIndexer::new(&index_path)?);\n    \n    // Create test data in multiple directories\n    let mut test_dirs = Vec::new();\n    for i in 0..5 {\n        let test_dir = temp_dir.path().join(format!(\"project_{}\", i));\n        create_test_project(&test_dir, 20)?;\n        test_dirs.push(test_dir);\n    }\n    \n    // Process multiple directories concurrently\n    let handles: Vec<_> = test_dirs.into_iter().map(|dir| {\n        let indexer = Arc::clone(&parallel_indexer);\n        std::thread::spawn(move || {\n            indexer.index_directory_parallel(&dir)\n        })\n    }).collect();\n    \n    // Wait for all threads to complete\n    let mut total_processed = 0;\n    for handle in handles {\n        let stats = handle.join().unwrap()?;\n        total_processed += stats.files_processed;\n    }\n    \n    // Should have processed files from all directories\n    assert!(total_processed > 0);\n    println!(\"Thread safety test processed {} files total\", total_processed);\n    \n    Ok(())\n}\n```\n\n### 5. Add error handling test\nAdd this test to validate error handling in parallel scenarios:\n```rust\n#[test]\nfn test_parallel_error_handling() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let index_path = temp_dir.path().join(\"index\");\n    let parallel_indexer = ParallelIndexer::new(&index_path)?;\n    \n    // Test with non-existent directory\n    let non_existent = temp_dir.path().join(\"does_not_exist\");\n    let result = parallel_indexer.index_directory_parallel(&non_existent);\n    assert!(result.is_err());\n    \n    // Test with file instead of directory\n    let file_path = temp_dir.path().join(\"not_a_dir.txt\");\n    std::fs::write(&file_path, \"content\")?;\n    let result = parallel_indexer.index_directory_parallel(&file_path);\n    assert!(result.is_err());\n    \n    // Test with permission-denied scenario (if possible to simulate)\n    // This is platform-specific and may not work on all systems\n    #[cfg(unix)]\n    {\n        let restricted_dir = temp_dir.path().join(\"restricted\");\n        std::fs::create_dir_all(&restricted_dir)?;\n        \n        // Remove read permissions\n        use std::os::unix::fs::PermissionsExt;\n        let mut perms = std::fs::metadata(&restricted_dir)?.permissions();\n        perms.set_mode(0o000);\n        std::fs::set_permissions(&restricted_dir, perms)?;\n        \n        let result = parallel_indexer.index_directory_parallel(&restricted_dir);\n        // May succeed or fail depending on system - just ensure it doesn't panic\n        let _ = result;\n        \n        // Restore permissions for cleanup\n        let mut perms = std::fs::metadata(&restricted_dir)?.permissions();\n        perms.set_mode(0o755);\n        std::fs::set_permissions(&restricted_dir, perms)?;\n    }\n    \n    Ok(())\n}\n```\n\n### 6. Add memory usage validation test\nAdd this test to ensure reasonable memory usage:\n```rust\n#[test]\nfn test_memory_usage() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let index_path = temp_dir.path().join(\"index\");\n    let parallel_indexer = ParallelIndexer::new(&index_path)?;\n    \n    // Create many small files\n    let test_project = temp_dir.path().join(\"memory_test\");\n    create_test_project(&test_project, 200)?;\n    \n    // Index and ensure it completes without memory issues\n    let stats = parallel_indexer.index_directory_parallel(&test_project)?;\n    \n    // Basic validation that processing completed\n    assert!(stats.files_processed > 0);\n    assert!(stats.total_size > 0);\n    \n    // Memory usage is hard to measure directly, but the test should complete\n    // without OOM errors, which would cause a panic\n    println!(\"Memory test completed: {}\", stats.summary());\n    \n    Ok(())\n}\n```\n\n## Success Criteria\n- [ ] Test data generation helpers create realistic project structures\n- [ ] Large-scale test processes 100+ files successfully\n- [ ] Thread safety test runs concurrent operations without issues\n- [ ] Error handling test validates all error conditions\n- [ ] Memory usage test completes without memory issues\n- [ ] All tests pass consistently\n- [ ] No compilation errors or warnings\n\n## Time Limit\n10 minutes\n\n## Notes\n- Test data should simulate real project structures\n- Performance tests help validate parallel benefits\n- Thread safety tests are crucial for parallel code\n- Error handling should be comprehensive and graceful\n- Memory tests help identify potential leaks or excessive usage