# Task 058: Concurrent Query Tests

## Context
You are implementing a comprehensive validation system for a Rust-based vector indexing system. This creates concurrent query tests that validates the system handles 100+ simultaneous users correctly.

## Project Structure
tests/
  concurrent_query_tests.rs  <- Create this file
src/
  validation/
  lib.rs
Cargo.toml

## Task Description
Create comprehensive tests for concurrent query handling including thread safety, resource contention, deadlock prevention, and performance under load.

## Requirements
1. Create comprehensive integration test
2. Test 100+ concurrent users
3. Validate thread safety and data consistency
4. Handle resource contention correctly
5. Ensure 10-minute completion scope

## Expected Code Structure
```rust
use anyhow::Result;
use tempfile::TempDir;
use std::sync::{Arc, atomic::{AtomicU64, AtomicBool, Ordering}};
use tokio::time::{Duration, Instant};
use std::collections::HashMap;

#[tokio::test]
async fn test_high_concurrency_queries() -> Result<()> {
    let temp_dir = TempDir::new()?;
    let test_generator = TestDataGenerator::new(temp_dir.path())?;
    
    // Generate dataset for concurrent testing
    let concurrent_dataset = test_generator.generate_concurrent_test_dataset(500).await?;
    let validator = CorrectnessValidator::new(&concurrent_dataset.index_path, &concurrent_dataset.vector_path).await?;
    
    let concurrent_users = 150;
    let queries_per_user = 20;
    
    let success_counter = Arc::new(AtomicU64::new(0));
    let error_counter = Arc::new(AtomicU64::new(0));
    let total_latency = Arc::new(AtomicU64::new(0));
    let max_latency = Arc::new(AtomicU64::new(0));
    
    let start_time = Instant::now();
    let mut handles = Vec::new();
    
    // Spawn concurrent users
    for user_id in 0..concurrent_users {\n        let validator_clone = validator.clone();\n        let success_counter_clone = success_counter.clone();\n        let error_counter_clone = error_counter.clone();\n        let total_latency_clone = total_latency.clone();\n        let max_latency_clone = max_latency.clone();\n        \n        let handle = tokio::spawn(async move {\n            for query_id in 0..queries_per_user {\n                let query = format!(\"concurrent_test_user_{}_query_{}\", user_id, query_id % 10);\n                let query_start = Instant::now();\n                \n                match validator_clone.search(&query).await {\n                    Ok(_) => {\n                        let latency = query_start.elapsed().as_millis() as u64;\n                        success_counter_clone.fetch_add(1, Ordering::SeqCst);\n                        total_latency_clone.fetch_add(latency, Ordering::SeqCst);\n                        max_latency_clone.fetch_max(latency, Ordering::SeqCst);\n                    },\n                    Err(_) => {\n                        error_counter_clone.fetch_add(1, Ordering::SeqCst);\n                    }\n                }\n                \n                // Small delay to prevent overwhelming\n                tokio::time::sleep(Duration::from_millis(10)).await;\n            }\n        });\n        handles.push(handle);\n    }\n    \n    // Wait for all concurrent queries to complete\n    for handle in handles {\n        handle.await?;\n    }\n    \n    let total_time = start_time.elapsed();\n    let successful_queries = success_counter.load(Ordering::SeqCst);\n    let failed_queries = error_counter.load(Ordering::SeqCst);\n    let total_queries = concurrent_users * queries_per_user;\n    let avg_latency = if successful_queries > 0 {\n        total_latency.load(Ordering::SeqCst) / successful_queries\n    } else { 0 };\n    let peak_latency = max_latency.load(Ordering::SeqCst);\n    \n    // Performance assertions\n    let success_rate = successful_queries as f64 / total_queries as f64;\n    assert!(success_rate >= 0.95, \"Success rate too low: {:.2}%\", success_rate * 100.0);\n    \n    let qps = successful_queries as f64 / total_time.as_secs_f64();\n    assert!(qps >= 200.0, \"Throughput too low under concurrency: {:.2} QPS\", qps);\n    \n    assert!(avg_latency <= 1000, \"Average latency too high: {}ms\", avg_latency);\n    assert!(peak_latency <= 5000, \"Peak latency too high: {}ms\", peak_latency);\n    \n    println!(\"High concurrency test: {}/{} queries successful, {:.2} QPS, {}ms avg latency, {}ms peak\", \n             successful_queries, total_queries, qps, avg_latency, peak_latency);\n    \n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_concurrent_read_write_operations() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let validator = CorrectnessValidator::new(&temp_dir.path().join(\"index\"), \n                                           &temp_dir.path().join(\"vectors\")).await?;\n    \n    let readers = 50;\n    let writers = 10;\n    let operations_per_worker = 20;\n    \n    let read_success = Arc::new(AtomicU64::new(0));\n    let write_success = Arc::new(AtomicU64::new(0));\n    let read_errors = Arc::new(AtomicU64::new(0));\n    let write_errors = Arc::new(AtomicU64::new(0));\n    let should_continue = Arc::new(AtomicBool::new(true));\n    \n    let mut handles = Vec::new();\n    \n    // Spawn reader tasks\n    for reader_id in 0..readers {\n        let validator_clone = validator.clone();\n        let read_success_clone = read_success.clone();\n        let read_errors_clone = read_errors.clone();\n        let continue_flag = should_continue.clone();\n        \n        let handle = tokio::spawn(async move {\n            let mut operation_count = 0;\n            while continue_flag.load(Ordering::SeqCst) && operation_count < operations_per_worker {\n                let query = format!(\"reader_{}_query_{}\", reader_id, operation_count);\n                \n                match validator_clone.search(&query).await {\n                    Ok(_) => read_success_clone.fetch_add(1, Ordering::SeqCst),\n                    Err(_) => read_errors_clone.fetch_add(1, Ordering::SeqCst),\n                };\n                \n                operation_count += 1;\n                tokio::time::sleep(Duration::from_millis(50)).await;\n            }\n        });\n        handles.push(handle);\n    }\n    \n    // Spawn writer tasks\n    for writer_id in 0..writers {\n        let validator_clone = validator.clone();\n        let write_success_clone = write_success.clone();\n        let write_errors_clone = write_errors.clone();\n        let continue_flag = should_continue.clone();\n        \n        let handle = tokio::spawn(async move {\n            let mut operation_count = 0;\n            while continue_flag.load(Ordering::SeqCst) && operation_count < operations_per_worker {\n                let document_content = format!(\"Writer {} document {} content with searchable terms\", \n                                             writer_id, operation_count);\n                let document_id = format!(\"writer_{}_{}\", writer_id, operation_count);\n                \n                match validator_clone.index_document(&document_id, &document_content).await {\n                    Ok(_) => write_success_clone.fetch_add(1, Ordering::SeqCst),\n                    Err(_) => write_errors_clone.fetch_add(1, Ordering::SeqCst),\n                };\n                \n                operation_count += 1;\n                tokio::time::sleep(Duration::from_millis(100)).await;\n            }\n        });\n        handles.push(handle);\n    }\n    \n    // Let operations run for a while\n    tokio::time::sleep(Duration::from_secs(30)).await;\n    should_continue.store(false, Ordering::SeqCst);\n    \n    // Wait for all tasks to complete\n    for handle in handles {\n        let _ = handle.await;\n    }\n    \n    let total_reads = read_success.load(Ordering::SeqCst);\n    let total_writes = write_success.load(Ordering::SeqCst);\n    let read_error_count = read_errors.load(Ordering::SeqCst);\n    let write_error_count = write_errors.load(Ordering::SeqCst);\n    \n    // Assertions for concurrent read/write\n    assert!(total_reads > 0, \"No successful reads in concurrent test\");\n    assert!(total_writes > 0, \"No successful writes in concurrent test\");\n    \n    let read_success_rate = total_reads as f64 / (total_reads + read_error_count) as f64;\n    let write_success_rate = total_writes as f64 / (total_writes + write_error_count) as f64;\n    \n    assert!(read_success_rate >= 0.90, \"Read success rate too low: {:.2}%\", read_success_rate * 100.0);\n    assert!(write_success_rate >= 0.85, \"Write success rate too low: {:.2}%\", write_success_rate * 100.0);\n    \n    println!(\"Concurrent read/write test: {} reads ({:.1}% success), {} writes ({:.1}% success)\", \n             total_reads, read_success_rate * 100.0, total_writes, write_success_rate * 100.0);\n    \n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_concurrent_different_query_types() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let test_generator = TestDataGenerator::new(temp_dir.path())?;\n    \n    let mixed_dataset = test_generator.generate_mixed_query_dataset().await?;\n    let validator = CorrectnessValidator::new(&mixed_dataset.index_path, &mixed_dataset.vector_path).await?;\n    \n    let concurrent_workers = 100;\n    let query_types = vec![\n        (\"text search\", vec![\"function\", \"class\", \"method\", \"variable\"]),\n        (\"boolean search\", vec![\"function AND test\", \"error OR exception\", \"async NOT sync\"]),\n        (\"wildcard search\", vec![\"test*\", \"*function\", \"*.rs\"]),\n        (\"phrase search\", vec![\"\\\"hello world\\\"\", \"\\\"test case\\\"\", \"\\\"error handling\\\"\"]),\n        (\"proximity search\", vec![\"function NEAR test\", \"error WITHIN 5 handling\"]),\n        (\"vector search\", vec![\"vector:programming\", \"vector:testing\", \"vector:error handling\"]),\n    ];\n    \n    let mut query_type_stats: HashMap<String, (AtomicU64, AtomicU64)> = HashMap::new();\n    for (query_type, _) in &query_types {\n        query_type_stats.insert(query_type.to_string(), (AtomicU64::new(0), AtomicU64::new(0)));\n    }\n    let query_type_stats = Arc::new(query_type_stats);\n    \n    let mut handles = Vec::new();\n    \n    for worker_id in 0..concurrent_workers {\n        let validator_clone = validator.clone();\n        let query_types_clone = query_types.clone();\n        let stats_clone = query_type_stats.clone();\n        \n        let handle = tokio::spawn(async move {\n            for i in 0..10 {\n                let (query_type, queries) = &query_types_clone[i % query_types_clone.len()];\n                let query = &queries[worker_id % queries.len()];\n                \n                let (success_counter, error_counter) = &stats_clone[*query_type];\n                \n                match validator_clone.search(query).await {\n                    Ok(_) => success_counter.fetch_add(1, Ordering::SeqCst),\n                    Err(_) => error_counter.fetch_add(1, Ordering::SeqCst),\n                };\n                \n                tokio::time::sleep(Duration::from_millis(20)).await;\n            }\n        });\n        handles.push(handle);\n    }\n    \n    // Wait for all concurrent mixed queries\n    for handle in handles {\n        handle.await?;\n    }\n    \n    // Verify results for each query type\n    for (query_type, (success_counter, error_counter)) in query_type_stats.iter() {\n        let successes = success_counter.load(Ordering::SeqCst);\n        let errors = error_counter.load(Ordering::SeqCst);\n        let total = successes + errors;\n        \n        if total > 0 {\n            let success_rate = successes as f64 / total as f64;\n            assert!(success_rate >= 0.80, \n                   \"Success rate too low for {}: {:.2}%\", query_type, success_rate * 100.0);\n            \n            println!(\"Concurrent {} queries: {}/{} successful ({:.1}%)\", \n                    query_type, successes, total, success_rate * 100.0);\n        }\n    }\n    \n    Ok(())\n}\n\n#[tokio::test]\nasync fn test_deadlock_prevention() -> Result<()> {\n    let temp_dir = TempDir::new()?;\n    let validator = CorrectnessValidator::new(&temp_dir.path().join(\"index\"), \n                                           &temp_dir.path().join(\"vectors\")).await?;\n    \n    let deadlock_workers = 20;\n    let operations_per_worker = 50;\n    \n    let completed_operations = Arc::new(AtomicU64::new(0));\n    let timeout_errors = Arc::new(AtomicU64::new(0));\n    \n    let mut handles = Vec::new();\n    \n    // Create potential deadlock scenario with mixed operations\n    for worker_id in 0..deadlock_workers {\n        let validator_clone = validator.clone();\n        let completed_clone = completed_operations.clone();\n        let timeout_clone = timeout_errors.clone();\n        \n        let handle = tokio::spawn(async move {\n            for op_id in 0..operations_per_worker {\n                // Mix of operations that could potentially deadlock\n                let operation_result = if op_id % 3 == 0 {\n                    // Search operation\n                    tokio::time::timeout(\n                        Duration::from_secs(10),\n                        validator_clone.search(&format!(\"deadlock_test_{}\", worker_id))\n                    ).await\n                } else if op_id % 3 == 1 {\n                    // Index operation\n                    tokio::time::timeout(\n                        Duration::from_secs(10),\n                        validator_clone.index_document(\n                            &format!(\"deadlock_doc_{}_{}\", worker_id, op_id),\n                            &format!(\"Content for deadlock test {} operation {}\", worker_id, op_id)\n                        )\n                    ).await\n                } else {\n                    // Mixed operation\n                    tokio::time::timeout(\n                        Duration::from_secs(10),\n                        validator_clone.search_and_update(&format!(\"deadlock_mixed_{}\", worker_id))\n                    ).await\n                };\n                \n                match operation_result {\n                    Ok(Ok(_)) => completed_clone.fetch_add(1, Ordering::SeqCst),\n                    Ok(Err(_)) => completed_clone.fetch_add(1, Ordering::SeqCst), // Completed but errored\n                    Err(_) => timeout_clone.fetch_add(1, Ordering::SeqCst), // Timeout (potential deadlock)\n                };\n                \n                tokio::time::sleep(Duration::from_millis(10)).await;\n            }\n        });\n        handles.push(handle);\n    }\n    \n    // Wait for all deadlock prevention tests\n    for handle in handles {\n        handle.await?;\n    }\n    \n    let total_completed = completed_operations.load(Ordering::SeqCst);\n    let total_timeouts = timeout_errors.load(Ordering::SeqCst);\n    let total_operations = deadlock_workers * operations_per_worker;\n    \n    // Deadlock prevention assertions\n    let completion_rate = total_completed as f64 / total_operations as f64;\n    assert!(completion_rate >= 0.95, \n           \"Too many operations failed to complete (potential deadlocks): {:.2}%\", \n           completion_rate * 100.0);\n    \n    assert!(total_timeouts < total_operations / 20, \n           \"Too many timeout errors (potential deadlocks): {}\", total_timeouts);\n    \n    println!(\"Deadlock prevention test: {}/{} operations completed, {} timeouts\", \n             total_completed, total_operations, total_timeouts);\n    \n    Ok(())\n}\n```\n\n## Success Criteria\n- 100+ concurrent users supported with 95%+ success rate\n- Throughput >= 200 QPS under high concurrency\n- Average latency <= 1000ms, peak latency <= 5000ms\n- Concurrent read/write operations work correctly\n- Different query types work concurrently without interference\n- Deadlock prevention works (95%+ completion rate)\n- Thread safety maintained under all concurrent scenarios\n- Resource contention handled gracefully\n- No data corruption or inconsistencies\n- Error rates stay below 5% under concurrent load\n\n## Time Limit\n10 minutes maximum