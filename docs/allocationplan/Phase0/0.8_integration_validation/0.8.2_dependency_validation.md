# Micro-Phase 0.8.2: Dependency Validation System

## Objective
Create an automated dependency validation system that ensures micro-phase prerequisites are met, validates completion criteria, and provides rollback mechanisms for failed tasks.

## Prerequisites
- Integration testing framework implemented (0.8.1 complete)
- All Phase 0 micro-phases documented
- CI/CD pipeline operational
- Project structure established

## Input
- All micro-phase documentation files
- Project workspace configuration
- Completion criteria definitions
- Dependency graph specifications

## Task Details

### Step 1: Create Dependency Graph Parser
Build a system to parse micro-phase dependencies from documentation and create a directed graph.

### Step 2: Implement Prerequisite Checker
Create automated validation that ensures all prerequisites are met before micro-phase execution.

### Step 3: Build Completion Validator
Implement verification system that confirms micro-phase success criteria are met.

### Step 4: Create Rollback Mechanism
Design system to safely revert changes when micro-phase execution fails.

### Step 5: Implement Dependency Enforcement
Build safeguards that prevent execution of dependent tasks when prerequisites fail.

## Expected Output
- Dependency validation utility (`tools/dependency_validator/`)
- Automated prerequisite checking system
- Completion criteria validation framework
- Rollback and recovery mechanisms
- CI integration for dependency enforcement

## Verification Steps
1. Run dependency validator on Phase 0 micro-phases
2. Test prerequisite checking with various scenarios
3. Verify completion validation catches incomplete tasks
4. Test rollback mechanisms with simulated failures
5. Confirm CI integration blocks invalid executions

## Time Estimate
50-65 minutes

## AI Execution Prompt
```
Create comprehensive dependency validation system for Phase 0 micro-phase execution.

1. Create dependency validation directory structure:
   ```bash
   mkdir -p tools/dependency_validator
   mkdir -p tools/dependency_validator/src
   mkdir -p tools/dependency_validator/tests
   mkdir -p tools/dependency_validator/config
   ```

2. Create tools/dependency_validator/Cargo.toml:

```toml
[package]
name = "dependency-validator"
version = "0.1.0"
edition = "2021"

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_yaml = "0.9"
walkdir = "2.0"
regex = "1.0"
anyhow = "1.0"
thiserror = "1.0"
clap = { version = "4.0", features = ["derive"] }
tokio = { version = "1.0", features = ["full"] }
petgraph = "0.6"
chrono = { version = "0.4", features = ["serde"] }

[dev-dependencies]
tempfile = "3.0"
```

3. Create tools/dependency_validator/src/main.rs:

```rust
//! Dependency Validation System for Cortesia Phase 0
//! 
//! This tool validates micro-phase dependencies, prerequisites, and completion
//! criteria to ensure safe and correct execution order.

use clap::{Parser, Subcommand};
use anyhow::Result;
use std::path::PathBuf;

mod dependency_graph;
mod prerequisite_checker;
mod completion_validator;
mod rollback_manager;
mod micro_phase_parser;

use dependency_graph::DependencyGraph;
use prerequisite_checker::PrerequisiteChecker;
use completion_validator::CompletionValidator;
use rollback_manager::RollbackManager;

#[derive(Parser)]
#[command(name = "dependency-validator")]
#[command(about = "Validates micro-phase dependencies and execution order")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// Parse micro-phase documents and build dependency graph
    Parse {
        /// Path to Phase 0 micro-phase directory
        #[arg(short, long)]
        phase_dir: PathBuf,
        /// Output dependency graph file
        #[arg(short, long)]
        output: Option<PathBuf>,
    },
    /// Check prerequisites for a specific micro-phase
    Check {
        /// Micro-phase identifier (e.g., "0.2.1")
        #[arg(short, long)]
        micro_phase: String,
        /// Path to project workspace
        #[arg(short, long)]
        workspace: PathBuf,
    },
    /// Validate completion of a micro-phase
    Validate {
        /// Micro-phase identifier
        #[arg(short, long)]
        micro_phase: String,
        /// Path to project workspace
        #[arg(short, long)]
        workspace: PathBuf,
    },
    /// Execute rollback for failed micro-phase
    Rollback {
        /// Micro-phase identifier to rollback
        #[arg(short, long)]
        micro_phase: String,
        /// Path to project workspace
        #[arg(short, long)]
        workspace: PathBuf,
        /// Create backup before rollback
        #[arg(short, long)]
        backup: bool,
    },
    /// Validate entire dependency chain
    ValidateChain {
        /// Path to Phase 0 micro-phase directory
        #[arg(short, long)]
        phase_dir: PathBuf,
        /// Path to project workspace
        #[arg(short, long)]
        workspace: PathBuf,
    },
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();
    
    match cli.command {
        Commands::Parse { phase_dir, output } => {
            let graph = DependencyGraph::from_directory(&phase_dir)?;
            
            if let Some(output_path) = output {
                graph.save_to_file(&output_path)?;
                println!("Dependency graph saved to: {}", output_path.display());
            } else {
                graph.print_summary();
            }
        }
        
        Commands::Check { micro_phase, workspace } => {
            let checker = PrerequisiteChecker::new(&workspace)?;
            let result = checker.check_prerequisites(&micro_phase).await?;
            
            if result.all_met() {
                println!("✅ All prerequisites met for {}", micro_phase);
            } else {
                println!("❌ Missing prerequisites for {}:", micro_phase);
                for missing in result.missing_prerequisites() {
                    println!("  - {}", missing);
                }
                std::process::exit(1);
            }
        }
        
        Commands::Validate { micro_phase, workspace } => {
            let validator = CompletionValidator::new(&workspace)?;
            let result = validator.validate_completion(&micro_phase).await?;
            
            if result.is_complete() {
                println!("✅ Micro-phase {} completed successfully", micro_phase);
            } else {
                println!("❌ Micro-phase {} incomplete:", micro_phase);
                for missing in result.missing_criteria() {
                    println!("  - {}", missing);
                }
                std::process::exit(1);
            }
        }
        
        Commands::Rollback { micro_phase, workspace, backup } => {
            let rollback_manager = RollbackManager::new(&workspace)?;
            
            if backup {
                let backup_path = rollback_manager.create_backup(&micro_phase).await?;
                println!("Backup created at: {}", backup_path.display());
            }
            
            rollback_manager.rollback_micro_phase(&micro_phase).await?;
            println!("✅ Rollback completed for {}", micro_phase);
        }
        
        Commands::ValidateChain { phase_dir, workspace } => {
            let graph = DependencyGraph::from_directory(&phase_dir)?;
            let checker = PrerequisiteChecker::new(&workspace)?;
            let validator = CompletionValidator::new(&workspace)?;
            
            let validation_result = validate_dependency_chain(&graph, &checker, &validator).await?;
            
            if validation_result.is_valid() {
                println!("✅ All dependency chains valid");
            } else {
                println!("❌ Dependency chain validation failed:");
                for error in validation_result.errors() {
                    println!("  - {}", error);
                }
                std::process::exit(1);
            }
        }
    }
    
    Ok(())
}

async fn validate_dependency_chain(
    graph: &DependencyGraph,
    checker: &PrerequisiteChecker,
    validator: &CompletionValidator,
) -> Result<ChainValidationResult> {
    let mut result = ChainValidationResult::new();
    
    // Check all micro-phases in topological order
    for micro_phase_id in graph.topological_order()? {
        // Check prerequisites
        let prereq_result = checker.check_prerequisites(&micro_phase_id).await?;
        if !prereq_result.all_met() {
            result.add_error(format!(
                "Prerequisites not met for {}: {:?}",
                micro_phase_id, prereq_result.missing_prerequisites()
            ));
            continue;
        }
        
        // Check completion if executed
        if validator.is_executed(&micro_phase_id).await? {
            let completion_result = validator.validate_completion(&micro_phase_id).await?;
            if !completion_result.is_complete() {
                result.add_error(format!(
                    "Completion criteria not met for {}: {:?}",
                    micro_phase_id, completion_result.missing_criteria()
                ));
            }
        }
    }
    
    Ok(result)
}

struct ChainValidationResult {
    errors: Vec<String>,
}

impl ChainValidationResult {
    fn new() -> Self {
        Self { errors: Vec::new() }
    }
    
    fn add_error(&mut self, error: String) {
        self.errors.push(error);
    }
    
    fn is_valid(&self) -> bool {
        self.errors.is_empty()
    }
    
    fn errors(&self) -> &[String] {
        &self.errors
    }
}
```

4. Create tools/dependency_validator/src/dependency_graph.rs:

```rust
//! Dependency graph construction and management

use anyhow::{Result, anyhow};
use petgraph::{Graph, Direction};
use petgraph::graph::NodeIndex;
use serde::{Serialize, Deserialize};
use std::collections::HashMap;
use std::path::{Path, PathBuf};
use walkdir::WalkDir;
use regex::Regex;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MicroPhase {
    pub id: String,
    pub title: String,
    pub prerequisites: Vec<String>,
    pub file_path: PathBuf,
    pub estimated_duration: Option<String>,
    pub success_criteria: Vec<String>,
}

#[derive(Debug)]
pub struct DependencyGraph {
    graph: Graph<MicroPhase, ()>,
    node_map: HashMap<String, NodeIndex>,
}

impl DependencyGraph {
    pub fn new() -> Self {
        Self {
            graph: Graph::new(),
            node_map: HashMap::new(),
        }
    }
    
    pub fn from_directory(phase_dir: &Path) -> Result<Self> {
        let mut graph = Self::new();
        
        // Parse all micro-phase files
        for entry in WalkDir::new(phase_dir) {
            let entry = entry?;
            let path = entry.path();
            
            if path.extension().map(|s| s == "md").unwrap_or(false) {
                if let Ok(micro_phase) = Self::parse_micro_phase_file(path) {
                    graph.add_micro_phase(micro_phase)?;
                }
            }
        }
        
        // Build dependency edges
        graph.build_dependency_edges()?;
        
        Ok(graph)
    }
    
    fn parse_micro_phase_file(file_path: &Path) -> Result<MicroPhase> {
        let content = std::fs::read_to_string(file_path)?;
        
        // Extract micro-phase ID from filename or content
        let id = Self::extract_id_from_filename(file_path)
            .or_else(|| Self::extract_id_from_content(&content))
            .ok_or_else(|| anyhow!("Could not extract micro-phase ID from {}", file_path.display()))?;
        
        // Extract title
        let title = Self::extract_title(&content)
            .unwrap_or_else(|| "Untitled Micro-Phase".to_string());
        
        // Extract prerequisites
        let prerequisites = Self::extract_prerequisites(&content);
        
        // Extract success criteria
        let success_criteria = Self::extract_success_criteria(&content);
        
        // Extract time estimate
        let estimated_duration = Self::extract_time_estimate(&content);
        
        Ok(MicroPhase {
            id,
            title,
            prerequisites,
            file_path: file_path.to_path_buf(),
            estimated_duration,
            success_criteria,
        })
    }
    
    fn extract_id_from_filename(file_path: &Path) -> Option<String> {
        let filename = file_path.file_stem()?.to_str()?;
        let re = Regex::new(r"(\d+\.\d+\.\d+)").ok()?;
        re.captures(filename)?.get(1)?.as_str().to_string().into()
    }
    
    fn extract_id_from_content(content: &str) -> Option<String> {
        let re = Regex::new(r"(?i)micro-phase\s+(\d+\.\d+\.\d+)").ok()?;
        re.captures(content)?.get(1)?.as_str().to_string().into()
    }
    
    fn extract_title(content: &str) -> Option<String> {
        let re = Regex::new(r"(?i)^#\s+(.+)$").ok()?;
        for line in content.lines() {
            if let Some(captures) = re.captures(line) {
                return Some(captures.get(1)?.as_str().to_string());
            }
        }
        None
    }
    
    fn extract_prerequisites(content: &str) -> Vec<String> {
        let mut prerequisites = Vec::new();
        
        // Look for Prerequisites section
        let re = Regex::new(r"(?i)## Prerequisites").unwrap();
        let mut in_prereq_section = false;
        
        for line in content.lines() {
            if re.is_match(line) {
                in_prereq_section = true;
                continue;
            }
            
            if in_prereq_section {
                // Stop at next section
                if line.starts_with("##") {
                    break;
                }
                
                // Extract prerequisite items
                if let Some(prereq) = Self::extract_prerequisite_from_line(line) {
                    prerequisites.push(prereq);
                }
            }
        }
        
        prerequisites
    }
    
    fn extract_prerequisite_from_line(line: &str) -> Option<String> {
        let line = line.trim();
        
        // Match bullet points or numbered items
        if line.starts_with("- ") || line.starts_with("* ") {
            return Some(line[2..].trim().to_string());
        }
        
        if line.chars().next()?.is_ascii_digit() && line.contains('.') {
            return Some(line.split('.').skip(1).collect::<Vec<_>>().join(".").trim().to_string());
        }
        
        None
    }
    
    fn extract_success_criteria(content: &str) -> Vec<String> {
        let mut criteria = Vec::new();
        
        // Look for Success Criteria section
        let re = Regex::new(r"(?i)## Success Criteria").unwrap();
        let mut in_criteria_section = false;
        
        for line in content.lines() {
            if re.is_match(line) {
                in_criteria_section = true;
                continue;
            }
            
            if in_criteria_section {
                // Stop at next section
                if line.starts_with("##") {
                    break;
                }
                
                // Extract criteria items
                if let Some(criterion) = Self::extract_criterion_from_line(line) {
                    criteria.push(criterion);
                }
            }
        }
        
        criteria
    }
    
    fn extract_criterion_from_line(line: &str) -> Option<String> {
        let line = line.trim();
        
        // Match checkboxes or bullet points
        if line.starts_with("- [ ]") || line.starts_with("- [x]") {
            return Some(line[5..].trim().to_string());
        }
        
        if line.starts_with("- ") || line.starts_with("* ") {
            return Some(line[2..].trim().to_string());
        }
        
        None
    }
    
    fn extract_time_estimate(content: &str) -> Option<String> {
        let re = Regex::new(r"(?i)## Time Estimate\s*\n\s*(.+)").ok()?;
        re.captures(content)?.get(1)?.as_str().to_string().into()
    }
    
    fn add_micro_phase(&mut self, micro_phase: MicroPhase) -> Result<()> {
        let node_index = self.graph.add_node(micro_phase.clone());
        self.node_map.insert(micro_phase.id.clone(), node_index);
        Ok(())
    }
    
    fn build_dependency_edges(&mut self) -> Result<()> {
        let micro_phases: Vec<_> = self.graph.node_weights().cloned().collect();
        
        for micro_phase in micro_phases {
            let dependent_node = self.node_map[&micro_phase.id];
            
            for prerequisite_id in &micro_phase.prerequisites {
                if let Some(&prerequisite_node) = self.node_map.get(prerequisite_id) {
                    self.graph.add_edge(prerequisite_node, dependent_node, ());
                }
            }
        }
        
        Ok(())
    }
    
    pub fn topological_order(&self) -> Result<Vec<String>> {
        use petgraph::algo::toposort;
        
        let sorted_nodes = toposort(&self.graph, None)
            .map_err(|_| anyhow!("Dependency graph contains cycles"))?;
        
        Ok(sorted_nodes
            .iter()
            .map(|&node_index| self.graph[node_index].id.clone())
            .collect())
    }
    
    pub fn get_dependencies(&self, micro_phase_id: &str) -> Option<Vec<String>> {
        let node_index = self.node_map.get(micro_phase_id)?;
        
        Some(
            self.graph
                .neighbors_directed(*node_index, Direction::Incoming)
                .map(|neighbor| self.graph[neighbor].id.clone())
                .collect()
        )
    }
    
    pub fn get_dependents(&self, micro_phase_id: &str) -> Option<Vec<String>> {
        let node_index = self.node_map.get(micro_phase_id)?;
        
        Some(
            self.graph
                .neighbors_directed(*node_index, Direction::Outgoing)
                .map(|neighbor| self.graph[neighbor].id.clone())
                .collect()
        )
    }
    
    pub fn save_to_file(&self, file_path: &Path) -> Result<()> {
        let serializable_graph: Vec<_> = self.graph.node_weights().collect();
        let json = serde_json::to_string_pretty(&serializable_graph)?;
        std::fs::write(file_path, json)?;
        Ok(())
    }
    
    pub fn print_summary(&self) {
        println!("Dependency Graph Summary:");
        println!("  Micro-phases: {}", self.graph.node_count());
        println!("  Dependencies: {}", self.graph.edge_count());
        
        if let Ok(topo_order) = self.topological_order() {
            println!("\nExecution Order:");
            for (i, micro_phase_id) in topo_order.iter().enumerate() {
                println!("  {}. {}", i + 1, micro_phase_id);
            }
        }
    }
}
```

5. Create tools/dependency_validator/src/prerequisite_checker.rs:

```rust
//! Prerequisite checking and validation

use anyhow::Result;
use std::path::{Path, PathBuf};
use serde::{Serialize, Deserialize};
use tokio::fs;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PrerequisiteCheckResult {
    micro_phase_id: String,
    missing_prerequisites: Vec<String>,
    all_prerequisites_met: bool,
}

impl PrerequisiteCheckResult {
    pub fn all_met(&self) -> bool {
        self.all_prerequisites_met
    }
    
    pub fn missing_prerequisites(&self) -> &[String] {
        &self.missing_prerequisites
    }
}

pub struct PrerequisiteChecker {
    workspace_path: PathBuf,
}

impl PrerequisiteChecker {
    pub fn new(workspace_path: &Path) -> Result<Self> {
        Ok(Self {
            workspace_path: workspace_path.to_path_buf(),
        })
    }
    
    pub async fn check_prerequisites(&self, micro_phase_id: &str) -> Result<PrerequisiteCheckResult> {
        let mut missing_prerequisites = Vec::new();
        
        // Check based on micro-phase ID pattern
        match micro_phase_id {
            id if id.starts_with("0.1.") => {
                missing_prerequisites.extend(self.check_project_setup_prerequisites().await?);
            }
            id if id.starts_with("0.2.") => {
                missing_prerequisites.extend(self.check_neuromorphic_core_prerequisites().await?);
            }
            id if id.starts_with("0.3.") => {
                missing_prerequisites.extend(self.check_ttfs_concepts_prerequisites().await?);
            }
            id if id.starts_with("0.4.") => {
                missing_prerequisites.extend(self.check_memory_branches_prerequisites().await?);
            }
            id if id.starts_with("0.5.") => {
                missing_prerequisites.extend(self.check_mock_infrastructure_prerequisites().await?);
            }
            id if id.starts_with("0.6.") => {
                missing_prerequisites.extend(self.check_benchmark_framework_prerequisites().await?);
            }
            id if id.starts_with("0.7.") => {
                missing_prerequisites.extend(self.check_ci_cd_prerequisites().await?);
            }
            id if id.starts_with("0.8.") => {
                missing_prerequisites.extend(self.check_integration_validation_prerequisites().await?);
            }
            _ => {
                missing_prerequisites.push(format!("Unknown micro-phase pattern: {}", micro_phase_id));
            }
        }
        
        Ok(PrerequisiteCheckResult {
            micro_phase_id: micro_phase_id.to_string(),
            all_prerequisites_met: missing_prerequisites.is_empty(),
            missing_prerequisites,
        })
    }
    
    async fn check_project_setup_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check for Rust toolchain
        if !self.check_rust_toolchain().await {
            missing.push("Rust toolchain not installed".to_string());
        }
        
        // Check for Git
        if !self.check_git_available().await {
            missing.push("Git not available".to_string());
        }
        
        // Check workspace directory exists
        if !self.workspace_path.exists() {
            missing.push("Workspace directory does not exist".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_neuromorphic_core_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check workspace Cargo.toml exists
        let cargo_toml = self.workspace_path.join("Cargo.toml");
        if !cargo_toml.exists() {
            missing.push("Workspace Cargo.toml not found".to_string());
        }
        
        // Check crates directory exists
        let crates_dir = self.workspace_path.join("crates");
        if !crates_dir.exists() {
            missing.push("Crates directory not found".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_ttfs_concepts_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check neuromorphic-core crate exists
        let core_crate = self.workspace_path.join("crates/neuromorphic-core");
        if !core_crate.exists() {
            missing.push("neuromorphic-core crate not found".to_string());
        }
        
        // Check core types are implemented
        let core_lib = core_crate.join("src/lib.rs");
        if core_lib.exists() {
            let content = fs::read_to_string(&core_lib).await?;
            if !content.contains("SpikingCorticalColumn") {
                missing.push("SpikingCorticalColumn not implemented in core".to_string());
            }
        }
        
        Ok(missing)
    }
    
    async fn check_memory_branches_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check temporal-memory crate exists
        let temporal_crate = self.workspace_path.join("crates/temporal-memory");
        if !temporal_crate.exists() {
            missing.push("temporal-memory crate not found".to_string());
        }
        
        // Check TTFS concepts are implemented
        let ttfs_file = self.workspace_path.join("crates/neuromorphic-core/src/ttfs_concept.rs");
        if !ttfs_file.exists() {
            missing.push("TTFS concepts not implemented".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_mock_infrastructure_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check all core components exist
        let required_crates = [
            "neuromorphic-core",
            "snn-allocation-engine", 
            "temporal-memory",
            "neural-bridge"
        ];
        
        for crate_name in &required_crates {
            let crate_path = self.workspace_path.join("crates").join(crate_name);
            if !crate_path.exists() {
                missing.push(format!("{} crate not found", crate_name));
            }
        }
        
        Ok(missing)
    }
    
    async fn check_benchmark_framework_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check mock infrastructure exists
        let mocks_crate = self.workspace_path.join("crates/snn-mocks");
        if !mocks_crate.exists() {
            missing.push("Mock infrastructure not implemented".to_string());
        }
        
        // Check benches directory exists
        let benches_dir = self.workspace_path.join("benches");
        if !benches_dir.exists() {
            missing.push("Benchmarks directory not found".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_ci_cd_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check benchmark framework exists
        let benchmark_files = self.workspace_path.join("benches");
        if !benchmark_files.exists() {
            missing.push("Benchmark framework not implemented".to_string());
        }
        
        // Check tests directory exists
        let tests_dir = self.workspace_path.join("tests");
        if !tests_dir.exists() {
            missing.push("Tests directory not found".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_integration_validation_prerequisites(&self) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        // Check CI/CD is operational
        let github_dir = self.workspace_path.join(".github");
        if !github_dir.exists() {
            missing.push("CI/CD pipeline not setup".to_string());
        }
        
        // Check all core components are complete
        if !self.check_cargo_workspace_valid().await {
            missing.push("Cargo workspace not valid".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_rust_toolchain(&self) -> bool {
        tokio::process::Command::new("rustc")
            .arg("--version")
            .output()
            .await
            .map(|output| output.status.success())
            .unwrap_or(false)
    }
    
    async fn check_git_available(&self) -> bool {
        tokio::process::Command::new("git")
            .arg("--version")
            .output()
            .await
            .map(|output| output.status.success())
            .unwrap_or(false)
    }
    
    async fn check_cargo_workspace_valid(&self) -> bool {
        let cargo_toml = self.workspace_path.join("Cargo.toml");
        if !cargo_toml.exists() {
            return false;
        }
        
        tokio::process::Command::new("cargo")
            .arg("check")
            .arg("--workspace")
            .current_dir(&self.workspace_path)
            .output()
            .await
            .map(|output| output.status.success())
            .unwrap_or(false)
    }
}
```

6. Create tools/dependency_validator/src/completion_validator.rs:

```rust
//! Completion criteria validation

use anyhow::Result;
use std::path::{Path, PathBuf};
use serde::{Serialize, Deserialize};
use tokio::fs;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct CompletionValidationResult {
    micro_phase_id: String,
    missing_criteria: Vec<String>,
    is_complete: bool,
}

impl CompletionValidationResult {
    pub fn is_complete(&self) -> bool {
        self.is_complete
    }
    
    pub fn missing_criteria(&self) -> &[String] {
        &self.missing_criteria
    }
}

pub struct CompletionValidator {
    workspace_path: PathBuf,
}

impl CompletionValidator {
    pub fn new(workspace_path: &Path) -> Result<Self> {
        Ok(Self {
            workspace_path: workspace_path.to_path_buf(),
        })
    }
    
    pub async fn is_executed(&self, micro_phase_id: &str) -> Result<bool> {
        // Check if micro-phase has been executed based on expected artifacts
        match micro_phase_id {
            "0.1.1" => Ok(self.workspace_path.join("Cargo.toml").exists()),
            "0.1.2" => Ok(self.workspace_path.join("crates/neuromorphic-core").exists()),
            "0.2.1" => Ok(self.workspace_path.join("crates/neuromorphic-core/src/spiking_column.rs").exists()),
            _ => Ok(false), // Default to not executed
        }
    }
    
    pub async fn validate_completion(&self, micro_phase_id: &str) -> Result<CompletionValidationResult> {
        let mut missing_criteria = Vec::new();
        
        match micro_phase_id {
            id if id.starts_with("0.1.") => {
                missing_criteria.extend(self.validate_project_setup_completion(id).await?);
            }
            id if id.starts_with("0.2.") => {
                missing_criteria.extend(self.validate_neuromorphic_core_completion(id).await?);
            }
            id if id.starts_with("0.3.") => {
                missing_criteria.extend(self.validate_ttfs_concepts_completion(id).await?);
            }
            id if id.starts_with("0.4.") => {
                missing_criteria.extend(self.validate_memory_branches_completion(id).await?);
            }
            id if id.starts_with("0.5.") => {
                missing_criteria.extend(self.validate_mock_infrastructure_completion(id).await?);
            }
            id if id.starts_with("0.6.") => {
                missing_criteria.extend(self.validate_benchmark_framework_completion(id).await?);
            }
            id if id.starts_with("0.7.") => {
                missing_criteria.extend(self.validate_ci_cd_completion(id).await?);
            }
            id if id.starts_with("0.8.") => {
                missing_criteria.extend(self.validate_integration_validation_completion(id).await?);
            }
            _ => {
                missing_criteria.push(format!("Unknown micro-phase for validation: {}", micro_phase_id));
            }
        }
        
        Ok(CompletionValidationResult {
            micro_phase_id: micro_phase_id.to_string(),
            is_complete: missing_criteria.is_empty(),
            missing_criteria,
        })
    }
    
    async fn validate_project_setup_completion(&self, micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        match micro_phase_id {
            "0.1.1" => {
                // Validate workspace creation
                if !self.workspace_path.join("Cargo.toml").exists() {
                    missing.push("Cargo.toml file not created".to_string());
                }
                
                if !self.check_cargo_workspace_valid().await {
                    missing.push("Cargo workspace invalid".to_string());
                }
            }
            "0.1.2" => {
                // Validate core crate creation
                let core_crate = self.workspace_path.join("crates/neuromorphic-core");
                if !core_crate.exists() {
                    missing.push("neuromorphic-core crate not created".to_string());
                }
                
                if !core_crate.join("Cargo.toml").exists() {
                    missing.push("Core crate Cargo.toml missing".to_string());
                }
            }
            _ => {}
        }
        
        Ok(missing)
    }
    
    async fn validate_neuromorphic_core_completion(&self, micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        match micro_phase_id {
            "0.2.3" => {
                // Validate spiking column implementation
                let spiking_column_file = self.workspace_path
                    .join("crates/neuromorphic-core/src/spiking_column.rs");
                
                if !spiking_column_file.exists() {
                    missing.push("spiking_column.rs not implemented".to_string());
                } else {
                    let content = fs::read_to_string(&spiking_column_file).await?;
                    
                    if !content.contains("SpikingCorticalColumn") {
                        missing.push("SpikingCorticalColumn struct not defined".to_string());
                    }
                    
                    if !content.contains("allocate_with_ttfs") {
                        missing.push("allocate_with_ttfs method not implemented".to_string());
                    }
                    
                    if !content.contains("is_in_refractory_period") {
                        missing.push("Refractory period management not implemented".to_string());
                    }
                }
            }
            _ => {}
        }
        
        Ok(missing)
    }
    
    async fn validate_ttfs_concepts_completion(&self, _micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        let ttfs_file = self.workspace_path
            .join("crates/neuromorphic-core/src/ttfs_concept.rs");
        
        if !ttfs_file.exists() {
            missing.push("ttfs_concept.rs not implemented".to_string());
        } else {
            let content = fs::read_to_string(&ttfs_file).await?;
            
            if !content.contains("TTFSConcept") {
                missing.push("TTFSConcept struct not defined".to_string());
            }
            
            if !content.contains("spike_encoded_properties") {
                missing.push("Spike encoding properties not implemented".to_string());
            }
        }
        
        Ok(missing)
    }
    
    async fn validate_memory_branches_completion(&self, _micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        let branch_file = self.workspace_path
            .join("crates/temporal-memory/src/branch.rs");
        
        if !branch_file.exists() {
            missing.push("branch.rs not implemented".to_string());
        } else {
            let content = fs::read_to_string(&branch_file).await?;
            
            if !content.contains("MemoryBranch") {
                missing.push("MemoryBranch struct not defined".to_string());
            }
            
            if !content.contains("ConsolidationState") {
                missing.push("ConsolidationState enum not defined".to_string());
            }
        }
        
        Ok(missing)
    }
    
    async fn validate_mock_infrastructure_completion(&self, _micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        let mocks_crate = self.workspace_path.join("crates/snn-mocks");
        if !mocks_crate.exists() {
            missing.push("snn-mocks crate not created".to_string());
        }
        
        Ok(missing)
    }
    
    async fn validate_benchmark_framework_completion(&self, _micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        let benches_dir = self.workspace_path.join("benches");
        if !benches_dir.exists() {
            missing.push("benches directory not created".to_string());
        }
        
        Ok(missing)
    }
    
    async fn validate_ci_cd_completion(&self, _micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        let ci_file = self.workspace_path.join(".github/workflows/ci.yml");
        if !ci_file.exists() {
            missing.push("CI workflow not created".to_string());
        }
        
        Ok(missing)
    }
    
    async fn validate_integration_validation_completion(&self, _micro_phase_id: &str) -> Result<Vec<String>> {
        let mut missing = Vec::new();
        
        let integration_tests = self.workspace_path.join("tests/integration");
        if !integration_tests.exists() {
            missing.push("Integration tests not created".to_string());
        }
        
        Ok(missing)
    }
    
    async fn check_cargo_workspace_valid(&self) -> bool {
        tokio::process::Command::new("cargo")
            .arg("check")
            .arg("--workspace")
            .current_dir(&self.workspace_path)
            .output()
            .await
            .map(|output| output.status.success())
            .unwrap_or(false)
    }
}
```

This dependency validation system provides comprehensive prerequisite checking, completion validation, and rollback mechanisms for Phase 0 micro-phases.
```

## Success Criteria
- [ ] Dependency validation utility created and functional
- [ ] Prerequisite checking system operational
- [ ] Completion criteria validation working
- [ ] Rollback mechanisms implemented and tested
- [ ] Dependency graph parsing functional
- [ ] CI integration prevents invalid executions

## Phase Integration Notes
This dependency validation system ensures:
1. **Execution Safety**: Prevents micro-phase execution when prerequisites aren't met
2. **Quality Assurance**: Validates that completion criteria are actually satisfied
3. **Error Recovery**: Provides rollback mechanisms for failed tasks
4. **Dependency Awareness**: Understands and enforces micro-phase dependencies
5. **CI Integration**: Blocks invalid or incomplete changes in continuous integration

## CLAUDE.md Synchronization Requirement
**CRITICAL**: After implementing this dependency validation system, verify that any existing `claude.md` files in the Phase 0 directory structure accurately reflect the new validation requirements and dependency enforcement patterns. Update documentation if:
- Validation criteria change from documented behavior
- New dependency requirements are introduced
- Rollback procedures differ from documented processes
- Integration patterns change from documented workflows