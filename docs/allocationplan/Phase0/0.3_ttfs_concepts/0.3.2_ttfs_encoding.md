# Micro-Phase 0.3.2: Implement TTFS Encoding Algorithm

## Objective
Implement the Time-to-First-Spike encoding algorithm that converts semantic features into spike patterns.

## Prerequisites
- TTFS concept types defined (0.3.1 complete)
- Understanding of spike encoding principles

## Input
- Semantic feature vectors
- TTFS encoding formula: t = -τ * ln(feature_strength)
- Encoding parameters (tau, thresholds)

## Task Details

### Step 1: Implement Core Encoding Algorithm
Create the mathematical encoding from features to spike times.

### Step 2: Add Multi-Neuron Encoding
Distribute features across multiple neurons for redundancy.

### Step 3: Implement Frequency Encoding
Add frequency-based encoding for feature magnitude.

### Step 4: Create Encoding Validation
Ensure encoded patterns meet biological constraints.

## Expected Output
- Complete `src/ttfs_concept/encoding.rs` implementation
- Encoding tests passing
- Biologically plausible spike patterns
- Performance within targets

## Verification Steps
1. Run `cargo test encoding` tests
2. Verify spike times follow TTFS formula
3. Check biological constraints are met
4. Confirm encoding is deterministic

## Time Estimate
40-50 minutes

## AI Execution Prompt
```
Implement the complete TTFS encoding algorithm.

1. Replace src/ttfs_concept/encoding.rs with full implementation:

```rust
//! TTFS encoding algorithms for converting features to spike patterns

use super::spike_pattern::{SpikePattern, SpikeEvent};
use std::time::Duration;

/// Configuration for TTFS encoding
#[derive(Debug, Clone)]
pub struct EncodingConfig {
    /// Maximum spike time (milliseconds)
    pub max_spike_time_ms: u64,
    
    /// Number of neurons per feature
    pub neurons_per_feature: u32,
    
    /// Time constant tau (milliseconds)
    pub tau_ms: f32,
    
    /// Minimum feature strength to encode
    pub min_feature_threshold: f32,
    
    /// Base frequency for encoding (Hz)
    pub base_frequency: f32,
    
    /// Frequency modulation depth
    pub frequency_modulation: f32,
    
    /// Enable population coding
    pub use_population_coding: bool,
}

impl Default for EncodingConfig {
    fn default() -> Self {
        Self {
            max_spike_time_ms: 100,
            neurons_per_feature: 3,
            tau_ms: 20.0,
            min_feature_threshold: 0.1,
            base_frequency: 40.0,
            frequency_modulation: 0.5,
            use_population_coding: true,
        }
    }
}

/// TTFS encoder for converting semantic features to spike patterns
pub struct TTFSEncoder {
    config: EncodingConfig,
    neuron_counter: std::sync::atomic::AtomicU32,
}

impl Default for TTFSEncoder {
    fn default() -> Self {
        Self::new(EncodingConfig::default())
    }
}

impl TTFSEncoder {
    /// Create new encoder with custom config
    pub fn new(config: EncodingConfig) -> Self {
        Self {
            config,
            neuron_counter: std::sync::atomic::AtomicU32::new(0),
        }
    }
    
    /// Encode feature vector into spike pattern
    pub fn encode(&self, features: &[f32]) -> SpikePattern {
        let mut events = Vec::new();
        
        for (feature_idx, &feature_value) in features.iter().enumerate() {
            // Skip weak features
            if feature_value.abs() < self.config.min_feature_threshold {
                continue;
            }
            
            // Encode using population coding or single neuron
            if self.config.use_population_coding {
                let feature_events = self.encode_feature_population(
                    feature_idx,
                    feature_value
                );
                events.extend(feature_events);
            } else {
                if let Some(event) = self.encode_feature_single(
                    feature_idx as u32,
                    feature_value
                ) {
                    events.push(event);
                }
            }
        }
        
        // Sort events by timestamp for proper ordering
        events.sort_by_key(|e| e.timestamp.as_nanos());
        
        SpikePattern::new(events)
    }
    
    /// Encode a single feature using population coding
    fn encode_feature_population(&self, 
                                feature_idx: usize, 
                                feature_value: f32) -> Vec<SpikeEvent> {
        let mut events = Vec::new();
        
        // Distribute encoding across multiple neurons
        for i in 0..self.config.neurons_per_feature {
            let neuron_id = (feature_idx as u32 * self.config.neurons_per_feature) + i;
            
            // Add slight variation to each neuron's encoding
            let jitter = (i as f32 / self.config.neurons_per_feature as f32) * 0.2;
            let adjusted_value = (feature_value + jitter).clamp(0.0, 1.0);
            
            if let Some(event) = self.encode_feature_single(neuron_id, adjusted_value) {
                events.push(event);
            }
        }
        
        events
    }
    
    /// Encode a single feature value to a spike event
    fn encode_feature_single(&self, neuron_id: u32, feature_value: f32) -> Option<SpikeEvent> {
        // Ensure feature is in valid range
        let clamped_value = feature_value.clamp(0.0, 1.0);
        
        if clamped_value < self.config.min_feature_threshold {
            return None;
        }
        
        // TTFS encoding: stronger features spike earlier
        // t = -τ * ln(feature_strength)
        let spike_time_ms = if clamped_value >= 0.99 {
            0.0 // Maximum strength = immediate spike
        } else {
            -self.config.tau_ms * (clamped_value).ln()
        };
        
        // Clamp to maximum time
        let spike_time_ms = spike_time_ms.clamp(0.0, self.config.max_spike_time_ms as f32);
        
        // Calculate frequency based on feature strength
        let frequency = self.calculate_frequency(clamped_value);
        
        Some(SpikeEvent {
            neuron_id,
            timestamp: Duration::from_micros((spike_time_ms * 1000.0) as u64),
            amplitude: clamped_value,
            frequency,
        })
    }
    
    /// Calculate spike frequency based on feature strength
    fn calculate_frequency(&self, feature_value: f32) -> f32 {
        // Base frequency modulated by feature strength
        let modulation = self.config.frequency_modulation * feature_value;
        self.config.base_frequency * (1.0 + modulation)
    }
    
    /// Encode with temporal context (for sequences)
    pub fn encode_temporal(&self, 
                          features: &[f32], 
                          time_offset: Duration) -> SpikePattern {
        let mut pattern = self.encode(features);
        
        // Shift all spikes by time offset
        for event in &mut pattern.events {
            event.timestamp += time_offset;
        }
        
        pattern.duration += time_offset;
        pattern
    }
    
    /// Validate that a spike pattern meets biological constraints
    pub fn validate_pattern(&self, pattern: &SpikePattern) -> Result<(), EncodingError> {
        // Check minimum inter-spike interval (refractory period)
        const MIN_ISI_MS: u64 = 2; // 2ms refractory period
        
        let mut events_by_neuron: std::collections::HashMap<u32, Vec<&SpikeEvent>> = 
            std::collections::HashMap::new();
        
        for event in &pattern.events {
            events_by_neuron.entry(event.neuron_id)
                .or_insert_with(Vec::new)
                .push(event);
        }
        
        for (neuron_id, neuron_events) in events_by_neuron {
            let mut sorted_events = neuron_events.clone();
            sorted_events.sort_by_key(|e| e.timestamp);
            
            for window in sorted_events.windows(2) {
                let isi = window[1].timestamp - window[0].timestamp;
                if isi < Duration::from_millis(MIN_ISI_MS) {
                    return Err(EncodingError::RefractoryViolation {
                        neuron_id,
                        isi,
                        minimum: Duration::from_millis(MIN_ISI_MS),
                    });
                }
            }
        }
        
        // Check maximum spike rate
        if pattern.density > 0.5 { // Max 0.5 spikes per ms
            return Err(EncodingError::ExcessiveSpikeRate(pattern.density));
        }
        
        Ok(())
    }
}

/// Errors that can occur during encoding
#[derive(Debug, thiserror::Error)]
pub enum EncodingError {
    #[error("Refractory period violation for neuron {neuron_id}: ISI {isi:?} < minimum {minimum:?}")]
    RefractoryViolation {
        neuron_id: u32,
        isi: Duration,
        minimum: Duration,
    },
    
    #[error("Excessive spike rate: {0} spikes/ms exceeds biological limits")]
    ExcessiveSpikeRate(f32),
    
    #[error("Invalid feature vector: {0}")]
    InvalidFeatures(String),
}

#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_ttfs_encoding_formula() {
        let encoder = TTFSEncoder::default();
        
        // Test edge cases
        let pattern1 = encoder.encode(&[1.0]); // Maximum strength
        assert_eq!(pattern1.first_spike_time(), Some(Duration::from_micros(0)));
        
        let pattern2 = encoder.encode(&[0.5]); // Medium strength
        let spike_time = pattern2.first_spike_time().unwrap();
        // Should be around -20 * ln(0.5) ≈ 13.86ms
        assert!(spike_time.as_millis() >= 10 && spike_time.as_millis() <= 20);
        
        let pattern3 = encoder.encode(&[0.05]); // Below threshold
        assert_eq!(pattern3.events.len(), 0);
    }
    
    #[test]
    fn test_population_coding() {
        let config = EncodingConfig {
            neurons_per_feature: 3,
            use_population_coding: true,
            ..Default::default()
        };
        
        let encoder = TTFSEncoder::new(config);
        let pattern = encoder.encode(&[0.8, 0.6]);
        
        // Should have 3 neurons per feature * 2 features = 6 spikes
        assert_eq!(pattern.events.len(), 6);
        
        // Check neuron IDs are correct
        let neuron_ids: std::collections::HashSet<_> = pattern.events.iter()
            .map(|e| e.neuron_id)
            .collect();
        assert_eq!(neuron_ids.len(), 6);
    }
    
    #[test]
    fn test_temporal_encoding() {
        let encoder = TTFSEncoder::default();
        let base_pattern = encoder.encode(&[0.7, 0.8]);
        
        let offset = Duration::from_millis(50);
        let temporal_pattern = encoder.encode_temporal(&[0.7, 0.8], offset);
        
        // All spikes should be shifted by offset
        for (base_event, temporal_event) in base_pattern.events.iter()
            .zip(temporal_pattern.events.iter()) {
            assert_eq!(temporal_event.timestamp, base_event.timestamp + offset);
        }
    }
    
    #[test]
    fn test_biological_constraints() {
        let encoder = TTFSEncoder::default();
        
        // Valid pattern
        let valid_pattern = encoder.encode(&[0.7, 0.8, 0.9]);
        assert!(encoder.validate_pattern(&valid_pattern).is_ok());
        
        // Create pattern with refractory violation
        let mut invalid_pattern = SpikePattern::new(vec![
            SpikeEvent {
                neuron_id: 1,
                timestamp: Duration::from_millis(0),
                amplitude: 1.0,
                frequency: 50.0,
            },
            SpikeEvent {
                neuron_id: 1,
                timestamp: Duration::from_millis(1), // Too close!
                amplitude: 1.0,
                frequency: 50.0,
            },
        ]);
        
        assert!(encoder.validate_pattern(&invalid_pattern).is_err());
    }
    
    #[test]
    fn test_frequency_modulation() {
        let encoder = TTFSEncoder::default();
        
        let weak_pattern = encoder.encode(&[0.2]);
        let strong_pattern = encoder.encode(&[0.9]);
        
        // Stronger features should have higher frequency
        assert!(strong_pattern.events[0].frequency > weak_pattern.events[0].frequency);
    }
}
```

2. Add unit conversion utilities to src/ttfs_concept/mod.rs:
```rust
//! TTFS-encoded concept representation

pub mod spike_pattern;
pub mod encoding;

// ... existing imports ...

/// Convert milliseconds to Duration
pub fn ms_to_duration(ms: f32) -> Duration {
    Duration::from_micros((ms * 1000.0) as u64)
}

/// Convert Duration to milliseconds
pub fn duration_to_ms(duration: Duration) -> f32 {
    duration.as_micros() as f32 / 1000.0
}

// ... rest of the file ...
```

3. Run tests:
   cd crates/neuromorphic-core
   cargo test ttfs_concept::encoding

All tests should pass, verifying the TTFS encoding implementation.
```

## Success Criteria
- [ ] TTFS encoding formula correctly implemented
- [ ] Population coding distributes across neurons
- [ ] Frequency modulation based on feature strength
- [ ] Biological constraints validated
- [ ] Temporal encoding supports sequences

## CLAUDE.md Synchronization Requirement
**CRITICAL**: After implementing the TTFS encoding algorithm, verify that any existing `claude.md` files in the neuromorphic-core crate directory accurately reflect the new encoding implementation. Update documentation if:
- TTFS encoding formula parameters differ from documented specifications
- Population coding behavior changes from documented algorithms
- Frequency modulation methods differ from documented approaches
- Biological constraint validation changes from documented rules
- Temporal encoding capabilities differ from documented features