# Micro-Phase 0.3.4: Implement Concept Similarity Metrics

## Objective
Create similarity comparison methods for TTFS concepts based on spike patterns and semantic features.

## Prerequisites
- TTFS concepts fully implemented (0.3.1-0.3.3 complete)
- Understanding of spike pattern similarity metrics

## Input
- Spike pattern distance metrics
- Semantic similarity algorithms
- Performance requirements (<1ms)

## Task Details

### Step 1: Implement Spike Pattern Distance
Create metrics for comparing spike patterns temporally.

### Step 2: Add Semantic Feature Similarity
Implement cosine similarity for feature vectors.

### Step 3: Create Hybrid Similarity
Combine spike and semantic similarities.

### Step 4: Add Caching for Performance
Cache similarity calculations for repeated comparisons.

## Expected Output
- `src/ttfs_concept/similarity.rs` file created
- Multiple similarity metrics implemented
- Performance optimizations in place
- Comprehensive tests

## Verification Steps
1. Run `cargo test similarity` tests
2. Verify similarity scores are in [0,1] range
3. Check performance meets <1ms target
4. Confirm caching improves repeated comparisons

## Time Estimate
30-40 minutes

## AI Execution Prompt
```
Implement concept similarity metrics for TTFS concepts.

1. Create src/ttfs_concept/similarity.rs:

```rust
//! Similarity metrics for TTFS concepts

use super::{TTFSConcept, SpikePattern, SpikeEvent};
use dashmap::DashMap;
use std::sync::Arc;
use std::time::Duration;

/// Configuration for similarity calculations
#[derive(Debug, Clone)]
pub struct SimilarityConfig {
    /// Weight for spike pattern similarity (0.0 to 1.0)
    pub spike_weight: f32,
    
    /// Weight for semantic feature similarity (0.0 to 1.0)
    pub semantic_weight: f32,
    
    /// Time window for spike matching (milliseconds)
    pub time_window_ms: f32,
    
    /// Enable similarity caching
    pub use_cache: bool,
}

impl Default for SimilarityConfig {
    fn default() -> Self {
        Self {
            spike_weight: 0.6,
            semantic_weight: 0.4,
            time_window_ms: 5.0,
            use_cache: true,
        }
    }
}

/// Similarity calculator for TTFS concepts
pub struct ConceptSimilarity {
    config: SimilarityConfig,
    cache: DashMap<(uuid::Uuid, uuid::Uuid), f32>,
}

impl ConceptSimilarity {
    /// Create new similarity calculator
    pub fn new(config: SimilarityConfig) -> Self {
        Self {
            config,
            cache: DashMap::new(),
        }
    }
    
    /// Calculate overall similarity between two concepts
    pub fn similarity(&self, concept1: &TTFSConcept, concept2: &TTFSConcept) -> f32 {
        // Check cache first
        if self.config.use_cache {
            let cache_key = Self::cache_key(concept1.id, concept2.id);
            if let Some(cached) = self.cache.get(&cache_key) {
                return *cached;
            }
        }
        
        // Calculate spike pattern similarity
        let spike_sim = self.spike_pattern_similarity(
            &concept1.spike_pattern,
            &concept2.spike_pattern
        );
        
        // Calculate semantic feature similarity
        let semantic_sim = self.semantic_similarity(
            &concept1.semantic_features,
            &concept2.semantic_features
        );
        
        // Weighted combination
        let total_weight = self.config.spike_weight + self.config.semantic_weight;
        let similarity = (self.config.spike_weight * spike_sim + 
                         self.config.semantic_weight * semantic_sim) / total_weight;
        
        // Cache result
        if self.config.use_cache {
            let cache_key = Self::cache_key(concept1.id, concept2.id);
            self.cache.insert(cache_key, similarity);
        }
        
        similarity
    }
    
    /// Calculate spike pattern similarity using Victor-Purpura metric
    pub fn spike_pattern_similarity(&self, pattern1: &SpikePattern, pattern2: &SpikePattern) -> f32 {
        if pattern1.events.is_empty() || pattern2.events.is_empty() {
            return 0.0;
        }
        
        // Calculate spike train distance
        let distance = self.victor_purpura_distance(
            &pattern1.events,
            &pattern2.events,
            self.config.time_window_ms
        );
        
        // Convert distance to similarity (exponential decay)
        (-distance / 10.0).exp()
    }
    
    /// Victor-Purpura spike train distance metric
    fn victor_purpura_distance(&self, 
                              spikes1: &[SpikeEvent], 
                              spikes2: &[SpikeEvent],
                              q: f32) -> f32 {
        let n = spikes1.len();
        let m = spikes2.len();
        
        // Dynamic programming table
        let mut dp = vec![vec![0.0; m + 1]; n + 1];
        
        // Initialize base cases
        for i in 0..=n {
            dp[i][0] = i as f32;
        }
        for j in 0..=m {
            dp[0][j] = j as f32;
        }
        
        // Fill table
        for i in 1..=n {
            for j in 1..=m {
                let spike1 = &spikes1[i - 1];
                let spike2 = &spikes2[j - 1];
                
                // Time difference in milliseconds
                let time_diff = (spike1.timestamp.as_millis() as f32 - 
                                spike2.timestamp.as_millis() as f32).abs();
                
                // Cost of shifting spike in time
                let shift_cost = time_diff / q;
                
                // Minimum of: delete spike1, delete spike2, or shift
                dp[i][j] = (dp[i-1][j] + 1.0)
                    .min(dp[i][j-1] + 1.0)
                    .min(dp[i-1][j-1] + shift_cost);
            }
        }
        
        dp[n][m]
    }
    
    /// Calculate semantic similarity using cosine similarity
    pub fn semantic_similarity(&self, features1: &[f32], features2: &[f32]) -> f32 {
        if features1.len() != features2.len() || features1.is_empty() {
            return 0.0;
        }
        
        // Cosine similarity
        let dot_product: f32 = features1.iter()
            .zip(features2.iter())
            .map(|(a, b)| a * b)
            .sum();
        
        let magnitude1 = features1.iter().map(|x| x * x).sum::<f32>().sqrt();
        let magnitude2 = features2.iter().map(|x| x * x).sum::<f32>().sqrt();
        
        if magnitude1 == 0.0 || magnitude2 == 0.0 {
            return 0.0;
        }
        
        (dot_product / (magnitude1 * magnitude2)).clamp(0.0, 1.0)
    }
    
    /// Find most similar concepts from a list
    pub fn find_most_similar(&self, 
                            target: &TTFSConcept, 
                            candidates: &[TTFSConcept],
                            top_k: usize) -> Vec<(uuid::Uuid, f32)> {
        let mut similarities: Vec<_> = candidates.iter()
            .filter(|c| c.id != target.id)
            .map(|candidate| {
                let sim = self.similarity(target, candidate);
                (candidate.id, sim)
            })
            .collect();
        
        // Sort by similarity (descending)
        similarities.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap());
        
        similarities.into_iter()
            .take(top_k)
            .collect()
    }
    
    /// Clear similarity cache
    pub fn clear_cache(&self) {
        self.cache.clear();
    }
    
    /// Get cache size
    pub fn cache_size(&self) -> usize {
        self.cache.len()
    }
    
    /// Create cache key (order-independent)
    fn cache_key(id1: uuid::Uuid, id2: uuid::Uuid) -> (uuid::Uuid, uuid::Uuid) {
        if id1 < id2 {
            (id1, id2)
        } else {
            (id2, id1)
        }
    }
}

/// Fast approximate similarity using LSH
pub struct FastSimilarity {
    hash_bits: usize,
    projection_matrix: Vec<Vec<f32>>,
}

impl FastSimilarity {
    /// Create new fast similarity calculator
    pub fn new(feature_dim: usize, hash_bits: usize) -> Self {
        use rand::Rng;
        let mut rng = rand::thread_rng();
        
        // Random projection matrix for LSH
        let projection_matrix = (0..hash_bits)
            .map(|_| {
                (0..feature_dim)
                    .map(|_| rng.gen_range(-1.0..1.0))
                    .collect()
            })
            .collect();
        
        Self {
            hash_bits,
            projection_matrix,
        }
    }
    
    /// Compute LSH hash for features
    pub fn compute_hash(&self, features: &[f32]) -> u64 {
        let mut hash = 0u64;
        
        for (i, projection) in self.projection_matrix.iter().enumerate() {
            let dot_product: f32 = features.iter()
                .zip(projection.iter())
                .map(|(a, b)| a * b)
                .sum();
            
            if dot_product > 0.0 {
                hash |= 1 << i;
            }
        }
        
        hash
    }
    
    /// Approximate similarity using Hamming distance
    pub fn approximate_similarity(&self, hash1: u64, hash2: u64) -> f32 {
        let xor = hash1 ^ hash2;
        let different_bits = xor.count_ones();
        let same_bits = self.hash_bits as u32 - different_bits;
        
        same_bits as f32 / self.hash_bits as f32
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::ttfs_concept::builder::ConceptBuilder;
    
    #[test]
    fn test_semantic_similarity() {
        let calc = ConceptSimilarity::new(SimilarityConfig::default());
        
        // Identical vectors
        let features1 = vec![0.5, 0.8, 0.3];
        let sim1 = calc.semantic_similarity(&features1, &features1);
        assert!((sim1 - 1.0).abs() < 0.001);
        
        // Orthogonal vectors
        let features2 = vec![1.0, 0.0, 0.0];
        let features3 = vec![0.0, 1.0, 0.0];
        let sim2 = calc.semantic_similarity(&features2, &features3);
        assert!(sim2.abs() < 0.001);
        
        // Similar vectors
        let features4 = vec![0.8, 0.6, 0.0];
        let features5 = vec![0.6, 0.8, 0.0];
        let sim3 = calc.semantic_similarity(&features4, &features5);
        assert!(sim3 > 0.9);
    }
    
    #[test]
    fn test_spike_pattern_similarity() {
        use crate::ttfs_concept::spike_pattern::SpikeEvent;
        
        let calc = ConceptSimilarity::new(SimilarityConfig::default());
        
        // Create similar spike patterns
        let events1 = vec![
            SpikeEvent {
                neuron_id: 1,
                timestamp: Duration::from_millis(10),
                amplitude: 0.8,
                frequency: 50.0,
            },
            SpikeEvent {
                neuron_id: 2,
                timestamp: Duration::from_millis(20),
                amplitude: 0.6,
                frequency: 40.0,
            },
        ];
        
        let events2 = vec![
            SpikeEvent {
                neuron_id: 1,
                timestamp: Duration::from_millis(12), // Slightly different
                amplitude: 0.8,
                frequency: 50.0,
            },
            SpikeEvent {
                neuron_id: 2,
                timestamp: Duration::from_millis(22), // Slightly different
                amplitude: 0.6,
                frequency: 40.0,
            },
        ];
        
        let pattern1 = SpikePattern::new(events1);
        let pattern2 = SpikePattern::new(events2);
        
        let similarity = calc.spike_pattern_similarity(&pattern1, &pattern2);
        assert!(similarity > 0.8); // Should be very similar
    }
    
    #[test]
    fn test_overall_similarity() {
        let concept1 = ConceptBuilder::new()
            .name("dog")
            .features(vec![0.8, 0.7, 0.6, 0.5])
            .build()
            .unwrap();
        
        let concept2 = ConceptBuilder::new()
            .name("wolf")
            .features(vec![0.7, 0.8, 0.6, 0.4])
            .build()
            .unwrap();
        
        let concept3 = ConceptBuilder::new()
            .name("table")
            .features(vec![0.1, 0.2, 0.9, 0.8])
            .build()
            .unwrap();
        
        let calc = ConceptSimilarity::new(SimilarityConfig::default());
        
        let sim_dog_wolf = calc.similarity(&concept1, &concept2);
        let sim_dog_table = calc.similarity(&concept1, &concept3);
        
        // Dog should be more similar to wolf than to table
        assert!(sim_dog_wolf > sim_dog_table);
    }
    
    #[test]
    fn test_caching() {
        let config = SimilarityConfig {
            use_cache: true,
            ..Default::default()
        };
        
        let calc = ConceptSimilarity::new(config);
        
        let concept1 = ConceptBuilder::new()
            .name("test1")
            .features(vec![0.5; 32])
            .build()
            .unwrap();
        
        let concept2 = ConceptBuilder::new()
            .name("test2")
            .features(vec![0.6; 32])
            .build()
            .unwrap();
        
        // First calculation
        let sim1 = calc.similarity(&concept1, &concept2);
        assert_eq!(calc.cache_size(), 1);
        
        // Second calculation (should use cache)
        let sim2 = calc.similarity(&concept1, &concept2);
        assert_eq!(sim1, sim2);
        assert_eq!(calc.cache_size(), 1);
        
        // Clear cache
        calc.clear_cache();
        assert_eq!(calc.cache_size(), 0);
    }
    
    #[test]
    fn test_fast_similarity() {
        let fast_sim = FastSimilarity::new(64, 16);
        
        let features1 = vec![0.5; 64];
        let features2 = vec![0.5; 64];
        let features3 = vec![0.1; 64];
        
        let hash1 = fast_sim.compute_hash(&features1);
        let hash2 = fast_sim.compute_hash(&features2);
        let hash3 = fast_sim.compute_hash(&features3);
        
        // Identical features should have same hash
        assert_eq!(hash1, hash2);
        
        // Different features should have different hash
        assert_ne!(hash1, hash3);
        
        let sim = fast_sim.approximate_similarity(hash1, hash3);
        assert!(sim >= 0.0 && sim <= 1.0);
    }
}
```

2. Update src/ttfs_concept/mod.rs:
```rust
//! TTFS-encoded concept representation

pub mod spike_pattern;
pub mod encoding;
pub mod builder;
pub mod similarity;

// ... existing imports ...

pub use similarity::{ConceptSimilarity, SimilarityConfig, FastSimilarity};

// ... rest of file ...
```

3. Add rand dependency to Cargo.toml:
   In [dependencies] section add:
   rand = "0.8"

4. Run tests:
   cd crates/neuromorphic-core
   cargo test ttfs_concept::similarity

All tests should pass.
```

## Success Criteria
- [ ] Spike pattern similarity using Victor-Purpura metric
- [ ] Semantic similarity using cosine distance
- [ ] Hybrid similarity combining both metrics
- [ ] Caching improves performance for repeated comparisons
- [ ] Fast approximate similarity using LSH