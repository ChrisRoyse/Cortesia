# Task 29: Comprehensive Error Handling Implementation

**Estimated Time**: 10-15 minutes  
**Dependencies**: 28_retrieval_service.md  
**Stage**: Service Layer  

## Objective
Implement a comprehensive error handling system that provides graceful degradation, detailed error classification, recovery mechanisms, and production-ready error monitoring for all Phase 3 components.

## Specific Requirements

### 1. Hierarchical Error Classification
- Structured error taxonomy with error codes and categories
- Context-aware error messages with actionable guidance
- Error severity levels and escalation policies
- Error correlation and root cause analysis

### 2. Recovery and Resilience Mechanisms
- Automatic retry logic with exponential backoff
- Circuit breaker pattern for failing components
- Graceful degradation for non-critical features
- Error propagation control and containment

### 3. Production-Ready Error Monitoring
- Structured error logging with correlation IDs
- Error rate monitoring and alerting thresholds
- Error trend analysis and anomaly detection
- Integration with external monitoring systems

## Implementation Steps

### 1. Create Error Type Hierarchy
```rust
// src/error/knowledge_graph_errors.rs
use std::fmt;
use std::error::Error as StdError;
use serde::{Serialize, Deserialize};
use uuid::Uuid;
use chrono::{DateTime, Utc};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct KnowledgeGraphError {
    pub error_id: String,
    pub error_code: ErrorCode,
    pub error_type: ErrorType,
    pub severity: ErrorSeverity,
    pub message: String,
    pub context: ErrorContext,
    pub timestamp: DateTime<Utc>,
    pub correlation_id: Option<String>,
    pub recoverable: bool,
    pub suggested_actions: Vec<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ErrorType {
    // Service Layer Errors
    AllocationError(AllocationErrorDetails),
    RetrievalError(RetrievalErrorDetails),
    ServiceError(ServiceErrorDetails),
    
    // Infrastructure Errors
    DatabaseError(DatabaseErrorDetails),
    NetworkError(NetworkErrorDetails),
    ResourceError(ResourceErrorDetails),
    
    // Neural Processing Errors
    TTFSError(TTFSErrorDetails),
    CorticalError(CorticalErrorDetails),
    InheritanceError(InheritanceErrorDetails),
    
    // Data Errors
    ValidationError(ValidationErrorDetails),
    SerializationError(SerializationErrorDetails),
    ConsistencyError(ConsistencyErrorDetails),
    
    // System Errors
    ConfigurationError(ConfigurationErrorDetails),
    PermissionError(PermissionErrorDetails),
    TimeoutError(TimeoutErrorDetails),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ErrorCode {
    // Allocation errors (1000-1999)
    AllocationPoolExhausted = 1001,
    AllocationStrategyFailed = 1002,
    MemoryFragmentationCritical = 1003,
    NeuralGuidanceUnavailable = 1004,
    
    // Retrieval errors (2000-2999)
    SearchTimeout = 2001,
    SemanticIndexCorrupted = 2002,
    TTFSEncodingFailed = 2003,
    SpreadingActivationFailed = 2004,
    
    // Service errors (3000-3999)
    ServiceUnavailable = 3001,
    CircuitBreakerOpen = 3002,
    RateLimitExceeded = 3003,
    ServiceConfigurationInvalid = 3004,
    
    // Database errors (4000-4999)
    DatabaseConnectionFailed = 4001,
    TransactionAborted = 4002,
    ConstraintViolation = 4003,
    IndexCorrupted = 4004,
    
    // Resource errors (5000-5999)
    ResourceExhausted = 5001,
    PermissionDenied = 5002,
    QuotaExceeded = 5003,
    DependencyUnavailable = 5004,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ErrorSeverity {
    Critical,    // Service cannot continue
    High,        // Major functionality impacted
    Medium,      // Partial functionality affected
    Low,         // Minor issues, service continues
    Warning,     // Potential issues, informational
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ErrorContext {
    pub operation: String,
    pub component: String,
    pub user_id: Option<String>,
    pub request_id: Option<String>,
    pub additional_data: std::collections::HashMap<String, String>,
}

impl KnowledgeGraphError {
    pub fn new(
        error_type: ErrorType,
        message: String,
        context: ErrorContext,
    ) -> Self {
        let (error_code, severity, recoverable, suggested_actions) = 
            Self::determine_error_properties(&error_type);
        
        Self {
            error_id: Uuid::new_v4().to_string(),
            error_code,
            error_type,
            severity,
            message,
            context,
            timestamp: Utc::now(),
            correlation_id: None,
            recoverable,
            suggested_actions,
        }
    }
    
    pub fn with_correlation_id(mut self, correlation_id: String) -> Self {
        self.correlation_id = Some(correlation_id);
        self
    }
    
    pub fn is_retryable(&self) -> bool {
        match self.error_code {
            ErrorCode::ServiceUnavailable |
            ErrorCode::DatabaseConnectionFailed |
            ErrorCode::SearchTimeout |
            ErrorCode::ResourceExhausted => true,
            _ => false,
        }
    }
    
    pub fn should_circuit_break(&self) -> bool {
        matches!(self.severity, ErrorSeverity::Critical | ErrorSeverity::High) &&
        matches!(self.error_code, 
            ErrorCode::ServiceUnavailable |
            ErrorCode::DatabaseConnectionFailed |
            ErrorCode::TTFSEncodingFailed |
            ErrorCode::SemanticIndexCorrupted
        )
    }
    
    fn determine_error_properties(error_type: &ErrorType) -> (ErrorCode, ErrorSeverity, bool, Vec<String>) {
        match error_type {
            ErrorType::AllocationError(details) => {
                match details {
                    AllocationErrorDetails::PoolExhausted => (
                        ErrorCode::AllocationPoolExhausted,
                        ErrorSeverity::High,
                        true,
                        vec![
                            "Increase memory pool size".to_string(),
                            "Review allocation patterns".to_string(),
                            "Consider memory cleanup".to_string(),
                        ]
                    ),
                    AllocationErrorDetails::StrategyFailed => (
                        ErrorCode::AllocationStrategyFailed,
                        ErrorSeverity::Medium,
                        true,
                        vec![
                            "Retry with different strategy".to_string(),
                            "Check neural guidance availability".to_string(),
                        ]
                    ),
                    _ => (ErrorCode::AllocationStrategyFailed, ErrorSeverity::Medium, true, vec![]),
                }
            },
            ErrorType::RetrievalError(details) => {
                match details {
                    RetrievalErrorDetails::SearchTimeout => (
                        ErrorCode::SearchTimeout,
                        ErrorSeverity::Medium,
                        true,
                        vec![
                            "Reduce search complexity".to_string(),
                            "Use cached results if available".to_string(),
                            "Try simpler search method".to_string(),
                        ]
                    ),
                    RetrievalErrorDetails::IndexCorrupted => (
                        ErrorCode::SemanticIndexCorrupted,
                        ErrorSeverity::Critical,
                        false,
                        vec![
                            "Rebuild semantic index".to_string(),
                            "Contact system administrator".to_string(),
                        ]
                    ),
                    _ => (ErrorCode::SearchTimeout, ErrorSeverity::Medium, true, vec![]),
                }
            },
            ErrorType::ServiceError(_) => (
                ErrorCode::ServiceUnavailable,
                ErrorSeverity::High,
                true,
                vec![
                    "Retry after brief delay".to_string(),
                    "Check service health status".to_string(),
                ]
            ),
            _ => (ErrorCode::ServiceUnavailable, ErrorSeverity::Medium, true, vec![]),
        }
    }
}

impl fmt::Display for KnowledgeGraphError {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        write!(f, "[{}] {} ({}): {}", 
            self.error_code as u32,
            self.error_type.to_string(),
            self.severity.to_string(),
            self.message
        )
    }
}

impl StdError for KnowledgeGraphError {}
```

### 2. Implement Error Recovery Manager
```rust
// src/error/recovery_manager.rs
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::time::sleep;

pub struct ErrorRecoveryManager {
    retry_strategies: HashMap<ErrorCode, RetryStrategy>,
    circuit_breakers: Arc<RwLock<HashMap<String, CircuitBreaker>>>,
    degradation_manager: Arc<GracefulDegradationManager>,
    monitoring: Arc<ErrorMonitoring>,
}

impl ErrorRecoveryManager {
    pub async fn handle_error<T, F, Fut>(
        &self,
        operation_name: &str,
        operation: F,
        context: ErrorContext,
    ) -> Result<T, KnowledgeGraphError>
    where
        F: Fn() -> Fut + Send + Sync,
        Fut: std::future::Future<Output = Result<T, KnowledgeGraphError>> + Send,
    {
        let mut attempts = 0;
        let max_attempts = 3;
        let mut last_error = None;
        
        while attempts < max_attempts {
            // Check circuit breaker
            if let Some(circuit_breaker) = self.circuit_breakers.read().await.get(operation_name) {
                if !circuit_breaker.can_execute() {
                    return Err(KnowledgeGraphError::new(
                        ErrorType::ServiceError(ServiceErrorDetails::CircuitBreakerOpen),
                        format!("Circuit breaker is open for operation: {}", operation_name),
                        context.clone(),
                    ));
                }
            }
            
            match operation().await {
                Ok(result) => {
                    // Record success
                    self.record_success(operation_name).await;
                    return Ok(result);
                },
                Err(error) => {
                    attempts += 1;
                    last_error = Some(error.clone());
                    
                    // Record failure
                    self.record_failure(operation_name, &error).await;
                    
                    // Check if error is retryable
                    if !error.is_retryable() || attempts >= max_attempts {
                        break;
                    }
                    
                    // Apply retry strategy
                    if let Some(strategy) = self.retry_strategies.get(&error.error_code) {
                        let delay = strategy.calculate_delay(attempts);
                        sleep(delay).await;
                    } else {
                        // Default exponential backoff
                        let delay = Duration::from_millis(100 * (2_u64.pow(attempts as u32 - 1)));
                        sleep(delay).await;
                    }
                }
            }
        }
        
        // All retries exhausted, try graceful degradation
        if let Some(error) = last_error {
            if let Some(degraded_result) = self.degradation_manager.attempt_degradation(&error, &context).await {
                return degraded_result;
            }
            Err(error)
        } else {
            Err(KnowledgeGraphError::new(
                ErrorType::ServiceError(ServiceErrorDetails::Unknown),
                "Operation failed with unknown error".to_string(),
                context,
            ))
        }
    }
    
    async fn record_success(&self, operation_name: &str) {
        if let Some(circuit_breaker) = self.circuit_breakers.write().await.get_mut(operation_name) {
            circuit_breaker.record_success();
        }
        self.monitoring.record_success(operation_name).await;
    }
    
    async fn record_failure(&self, operation_name: &str, error: &KnowledgeGraphError) {
        if let Some(circuit_breaker) = self.circuit_breakers.write().await.get_mut(operation_name) {
            if error.should_circuit_break() {
                circuit_breaker.record_failure();
            }
        }
        self.monitoring.record_error(operation_name, error).await;
    }
}

#[derive(Debug, Clone)]
pub struct RetryStrategy {
    pub max_attempts: usize,
    pub base_delay: Duration,
    pub max_delay: Duration,
    pub backoff_factor: f64,
    pub jitter: bool,
}

impl RetryStrategy {
    pub fn calculate_delay(&self, attempt: usize) -> Duration {
        let delay = self.base_delay.as_millis() as f64 * self.backoff_factor.powi(attempt as i32 - 1);
        let delay = delay.min(self.max_delay.as_millis() as f64);
        
        let delay = if self.jitter {
            let jitter_factor = 1.0 + (rand::random::<f64>() - 0.5) * 0.1; // Â±5% jitter
            delay * jitter_factor
        } else {
            delay
        };
        
        Duration::from_millis(delay as u64)
    }
}
```

### 3. Implement Error Monitoring
```rust
// src/error/monitoring.rs
pub struct ErrorMonitoring {
    error_storage: Arc<RwLock<Vec<ErrorRecord>>>,
    metrics_collector: Arc<ErrorMetricsCollector>,
    alert_manager: Arc<AlertManager>,
    trend_analyzer: Arc<ErrorTrendAnalyzer>,
}

impl ErrorMonitoring {
    pub async fn record_error(&self, operation: &str, error: &KnowledgeGraphError) {
        let error_record = ErrorRecord {
            timestamp: Utc::now(),
            operation: operation.to_string(),
            error: error.clone(),
        };
        
        // Store error record
        self.error_storage.write().await.push(error_record.clone());
        
        // Update metrics
        self.metrics_collector.record_error(&error_record).await;
        
        // Check for alert conditions
        self.alert_manager.check_alert_conditions(&error_record).await;
        
        // Analyze trends
        self.trend_analyzer.analyze_error_trend(&error_record).await;
    }
    
    pub async fn get_error_dashboard(&self) -> ErrorDashboard {
        ErrorDashboard {
            recent_errors: self.get_recent_errors(24).await, // Last 24 hours
            error_rate_trends: self.metrics_collector.get_rate_trends().await,
            top_error_types: self.metrics_collector.get_top_error_types().await,
            system_health_score: self.calculate_health_score().await,
            active_alerts: self.alert_manager.get_active_alerts().await,
        }
    }
    
    async fn calculate_health_score(&self) -> f64 {
        let recent_errors = self.get_recent_errors(1).await; // Last hour
        let total_operations = self.metrics_collector.get_total_operations_last_hour().await;
        
        if total_operations == 0 {
            return 1.0; // Perfect health if no operations
        }
        
        let error_rate = recent_errors.len() as f64 / total_operations as f64;
        
        // Convert error rate to health score (0-1, where 1 is perfect health)
        (1.0 - error_rate.min(1.0)).max(0.0)
    }
}
```

### 4. Integrate Error Handling into Services
```rust
// src/services/service_integration.rs
impl KnowledgeGraphService {
    pub async fn allocate_memory_with_error_handling(
        &self,
        request: MemoryAllocationRequest,
    ) -> Result<AllocationResult, KnowledgeGraphError> {
        let context = ErrorContext {
            operation: "memory_allocation".to_string(),
            component: "knowledge_graph_service".to_string(),
            user_id: request.user_id.clone(),
            request_id: Some(request.request_id.clone()),
            additional_data: HashMap::new(),
        };
        
        self.error_recovery_manager.handle_error(
            "allocate_memory",
            || async {
                self.execute_memory_allocation(request.clone()).await
                    .map_err(|e| self.convert_allocation_error(e, &context))
            },
            context,
        ).await
    }
    
    fn convert_allocation_error(
        &self,
        error: AllocationError,
        context: &ErrorContext,
    ) -> KnowledgeGraphError {
        let error_type = match error {
            AllocationError::PoolExhausted => {
                ErrorType::AllocationError(AllocationErrorDetails::PoolExhausted)
            },
            AllocationError::StrategyFailed => {
                ErrorType::AllocationError(AllocationErrorDetails::StrategyFailed)
            },
            AllocationError::NeuralGuidanceUnavailable => {
                ErrorType::AllocationError(AllocationErrorDetails::NeuralGuidanceUnavailable)
            },
            _ => ErrorType::AllocationError(AllocationErrorDetails::Unknown),
        };
        
        KnowledgeGraphError::new(
            error_type,
            error.to_string(),
            context.clone(),
        )
    }
}
```

## Acceptance Criteria

### Functional Requirements
- [ ] Error classification system categorizes all error types correctly
- [ ] Retry mechanisms work with appropriate backoff strategies
- [ ] Circuit breakers protect against cascading failures
- [ ] Graceful degradation provides fallback functionality
- [ ] Error monitoring captures and analyzes error patterns

### Performance Requirements
- [ ] Error handling adds < 1ms overhead to normal operations
- [ ] Error recovery attempts complete within reasonable timeframes
- [ ] Error monitoring doesn't impact system performance
- [ ] Memory usage for error tracking stays bounded

### Testing Requirements
- [ ] Unit tests for all error types and recovery scenarios
- [ ] Integration tests for error propagation
- [ ] Chaos engineering tests for failure scenarios
- [ ] Performance tests for error handling overhead

## Validation Steps

1. **Test error creation and handling**:
   ```rust
   let error = KnowledgeGraphError::new(error_type, message, context);
   assert!(error.is_retryable());
   ```

2. **Test recovery manager**:
   ```rust
   let result = recovery_manager.handle_error("test_op", operation, context).await;
   ```

3. **Run error handling tests**:
   ```bash
   cargo test error_handling_tests
   ```

## Files to Create/Modify
- `src/error/knowledge_graph_errors.rs` - Error type definitions
- `src/error/recovery_manager.rs` - Error recovery logic
- `src/error/monitoring.rs` - Error monitoring and analytics
- `tests/error/error_handling_tests.rs` - Comprehensive test suite

## Success Metrics
- Error recovery success rate: > 90%
- Mean time to recovery: < 5 seconds
- False positive alert rate: < 5%
- System uptime improvement: > 99.5%

## Next Task
Upon completion, proceed to **30_api_endpoints.md** to create REST/GraphQL API endpoints.