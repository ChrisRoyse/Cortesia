# Micro Phase 6.1: Full System Integration Tests

**Estimated Time**: 45 minutes
**Dependencies**: Task 4.5 Complete (Compression Metrics)
**Objective**: Create comprehensive end-to-end integration tests that validate the complete inheritance system

## Task Description

Develop comprehensive integration tests that verify all Phase 4 components work together correctly, achieving the 10x compression target while maintaining 100% semantic correctness.

## Deliverables

Create `tests/integration/phase_4_complete_system.rs` with:

1. **End-to-end workflow tests**: Complete compression pipeline
2. **Performance integration tests**: All components working together
3. **Semantic preservation tests**: Zero information loss verification
4. **Stress tests**: Large-scale system behavior
5. **Edge case handling**: Complex inheritance scenarios

## Success Criteria

- [ ] Achieves 10x compression target on test hierarchies
- [ ] Property lookup remains < 100Î¼s throughout workflow
- [ ] 100% semantic preservation verified
- [ ] Handles hierarchies with 50,000+ nodes
- [ ] All edge cases pass without errors
- [ ] Memory usage remains bounded under stress

## Implementation Requirements

```rust
#[cfg(test)]
mod phase_4_integration_tests {
    use super::*;
    use std::collections::HashMap;
    use std::time::{Duration, Instant};
    
    #[test]
    fn test_complete_compression_workflow() {
        // Test the full pipeline: Creation -> Compression -> Optimization -> Metrics
    }
    
    #[test]
    fn test_10x_compression_target() {
        // Verify the main success criteria
    }
    
    #[test]
    fn test_semantic_preservation_end_to_end() {
        // Ensure no meaning is lost through the entire pipeline
    }
    
    #[test]
    fn test_performance_under_load() {
        // Verify performance with large hierarchies
    }
    
    #[test]
    fn test_complex_inheritance_scenarios() {
        // Multiple inheritance, deep hierarchies, conflicts
    }
    
    #[test]
    fn test_system_stress_conditions() {
        // Memory pressure, concurrent access, edge cases
    }
}

struct IntegrationTestSuite {
    test_hierarchies: Vec<TestHierarchy>,
    performance_benchmarks: Vec<PerformanceBenchmark>,
    validation_rules: Vec<ValidationRule>,
}

struct TestHierarchy {
    name: String,
    node_count: usize,
    expected_compression_ratio: f64,
    complexity_factors: Vec<ComplexityFactor>,
}

#[derive(Debug)]
enum ComplexityFactor {
    DeepInheritance(u32),      // Max depth
    MultipleInheritance(u32),  // Max parents per node
    PropertyDensity(f32),      // Properties per node
    ExceptionRate(f32),        // Expected exception rate
}
```

## Test Requirements

Must pass all integration scenarios:
```rust
#[test]
fn test_complete_compression_workflow() {
    // Create large, complex hierarchy
    let mut hierarchy = create_realistic_knowledge_hierarchy(10000);
    
    // Record initial state
    let initial_size = hierarchy.calculate_storage_size();
    let initial_properties = collect_all_property_values(&hierarchy);
    
    // Step 1: Property Resolution and Caching
    let resolver = PropertyResolver::new(ResolutionStrategy::DepthFirst);
    let cache = PropertyCache::new(50000, Duration::from_secs(300));
    
    // Verify initial property resolution works
    for node in hierarchy.sample_nodes(100) {
        for property in node.all_property_names() {
            let value = resolver.resolve_property(&hierarchy, node.id, &property);
            assert!(value.is_some());
        }
    }
    
    // Step 2: Exception Detection and Storage
    let exception_detector = ExceptionDetector::new(0.8, 0.7);
    let exception_store = ExceptionStore::new();
    
    for node in hierarchy.all_nodes() {
        let inherited = resolver.get_all_inherited_properties(&hierarchy, node.id);
        let exceptions = exception_detector.detect_node_exceptions(&node, &inherited);
        
        for (prop, exception) in exceptions {
            exception_store.add_exception(node.id, prop, exception);
        }
    }
    
    // Step 3: Property Compression
    let analyzer = PropertyAnalyzer::new(0.7, 5);
    let promoter = PropertyPromoter::new(PromotionStrategy::Balanced);
    let compressor = PropertyCompressor::new(analyzer, promoter);
    
    let compression_result = compressor.compress(&mut hierarchy);
    
    // Step 4: Hierarchy Optimization
    let reorganizer = HierarchyReorganizer::new(0.8);
    let optimization_result = reorganizer.reorganize_hierarchy(&mut hierarchy);
    
    // Step 5: Final Metrics and Validation
    let metrics_calculator = CompressionMetricsCalculator::new();
    let final_metrics = metrics_calculator.calculate_comprehensive_metrics(&hierarchy);
    
    // Verify compression target achieved
    assert!(final_metrics.compression_ratio >= 10.0, 
        "Compression ratio {} below target of 10x", final_metrics.compression_ratio);
    
    // Verify semantic preservation
    let final_properties = collect_all_property_values(&hierarchy);
    assert_eq!(initial_properties, final_properties, 
        "Property values changed during compression");
    
    // Verify performance maintained
    let sample_node = NodeId(9999);
    let start = Instant::now();
    for _ in 0..1000 {
        resolver.resolve_property(&hierarchy, sample_node, "test_property");
    }
    let avg_time = start.elapsed() / 1000;
    assert!(avg_time < Duration::from_micros(100), 
        "Property resolution too slow: {:?}", avg_time);
    
    // Verify storage reduction
    let final_size = hierarchy.calculate_storage_size();
    assert!(final_size < initial_size / 10, 
        "Storage not reduced enough: {} -> {}", initial_size, final_size);
}

#[test]
fn test_semantic_preservation_end_to_end() {
    let test_cases = vec![
        create_animal_taxonomy_hierarchy(),
        create_programming_language_hierarchy(),
        create_geographical_hierarchy(),
        create_scientific_classification_hierarchy(),
    ];
    
    for (i, original_hierarchy) in test_cases.into_iter().enumerate() {
        let mut test_hierarchy = original_hierarchy.clone();
        
        // Record all possible queries before compression
        let mut test_queries = Vec::new();
        for node in original_hierarchy.all_nodes() {
            for property in get_all_possible_properties(&original_hierarchy) {
                let value = original_hierarchy.get_property(node.id, &property);
                test_queries.push((node.id, property, value));
            }
        }
        
        // Run complete compression pipeline
        run_complete_compression_pipeline(&mut test_hierarchy);
        
        // Verify every query produces the same result
        for (node_id, property, expected_value) in test_queries {
            let actual_value = test_hierarchy.get_property(node_id, &property);
            assert_eq!(actual_value, expected_value, 
                "Test case {}: Property '{}' on node {:?} changed from {:?} to {:?}",
                i, property, node_id, expected_value, actual_value);
        }
    }
}

#[test]
fn test_performance_under_load() {
    let hierarchy = create_large_hierarchy(50000); // 50k nodes
    
    // Test concurrent access during compression
    let compression_thread = thread::spawn({
        let mut h = hierarchy.clone();
        move || {
            let compressor = PropertyCompressor::new(
                PropertyAnalyzer::new(0.7, 10),
                PropertyPromoter::new(PromotionStrategy::Balanced)
            );
            compressor.compress(&mut h)
        }
    });
    
    // Simultaneous query threads
    let query_threads: Vec<_> = (0..8).map(|_| {
        let h = hierarchy.clone();
        thread::spawn(move || {
            let resolver = PropertyResolver::new(ResolutionStrategy::DepthFirst);
            for _ in 0..1000 {
                let node = NodeId(rand::random::<u64>() % 50000);
                resolver.resolve_property(&h, node, "random_property");
            }
        })
    }).collect();
    
    // Wait for completion
    let compression_result = compression_thread.join().unwrap();
    for thread in query_threads {
        thread.join().unwrap();
    }
    
    // Verify compression still achieved target
    assert!(compression_result.compression_ratio >= 10.0);
    
    // Test post-compression performance
    let resolver = PropertyResolver::new(ResolutionStrategy::DepthFirst);
    let start = Instant::now();
    for i in 0..10000 {
        let node = NodeId(i % 50000);
        resolver.resolve_property(&hierarchy, node, "common_property");
    }
    let elapsed = start.elapsed();
    
    let avg_time = elapsed / 10000;
    assert!(avg_time < Duration::from_micros(100));
}

#[test]
fn test_complex_inheritance_scenarios() {
    // Test 1: Deep diamond inheritance (8 levels)
    let mut deep_diamond = create_deep_diamond_hierarchy(8);
    run_complete_compression_pipeline(&mut deep_diamond);
    verify_diamond_resolution_correctness(&deep_diamond);
    
    // Test 2: Wide multiple inheritance (16 parents)
    let mut wide_multiple = create_wide_multiple_inheritance(16);
    run_complete_compression_pipeline(&mut wide_multiple);
    verify_multiple_inheritance_determinism(&wide_multiple);
    
    // Test 3: Cyclical references (should be detected and handled)
    let mut cyclical = create_hierarchy_with_potential_cycles();
    run_complete_compression_pipeline(&mut cyclical);
    verify_no_infinite_loops(&cyclical);
    
    // Test 4: Massive fan-out (1000 children under one parent)
    let mut massive_fanout = create_massive_fanout_hierarchy(1000);
    run_complete_compression_pipeline(&mut massive_fanout);
    verify_fanout_optimization(&massive_fanout);
}

#[test]
fn test_system_stress_conditions() {
    // Test 1: Memory pressure
    test_memory_pressure_handling();
    
    // Test 2: Concurrent modifications
    test_concurrent_modifications();
    
    // Test 3: Malformed hierarchies
    test_malformed_hierarchy_handling();
    
    // Test 4: Performance degradation bounds
    test_performance_degradation_bounds();
}

fn test_memory_pressure_handling() {
    // Create hierarchy that approaches memory limits
    let mut hierarchy = create_memory_intensive_hierarchy();
    
    // Monitor memory usage throughout compression
    let initial_memory = get_process_memory_usage();
    
    run_complete_compression_pipeline(&mut hierarchy);
    
    let final_memory = get_process_memory_usage();
    
    // Memory should not grow unboundedly
    let memory_growth = final_memory - initial_memory;
    assert!(memory_growth < 100 * 1024 * 1024); // < 100MB growth
}

fn run_complete_compression_pipeline(hierarchy: &mut InheritanceHierarchy) {
    // Standardized pipeline for all tests
    let analyzer = PropertyAnalyzer::new(0.7, 5);
    let promoter = PropertyPromoter::new(PromotionStrategy::Balanced);
    let compressor = PropertyCompressor::new(analyzer, promoter);
    
    let _compression_result = compressor.compress(hierarchy);
    
    let reorganizer = HierarchyReorganizer::new(0.8);
    let _optimization_result = reorganizer.reorganize_hierarchy(hierarchy);
}
```

## File Location
`tests/integration/phase_4_complete_system.rs`

## Next Micro Phase
After completion, proceed to Micro 6.2: End-to-End Workflow Tests