# Refactored Comprehensive Testing Prompt for LLMKG Cognitive Algorithms

## Overview

You are tasked with creating a comprehensive test suite for the LLMKG (Lightning-Fast Knowledge Graph) system's MCP (Model Context Protocol) servers and cognitive algorithms. The system is designed to provide LLMs with human-like intelligence by giving them access to advanced cognitive reasoning tools through MCP interfaces. 

**Key Architecture Understanding**: LLMs connect to LLMKG via MCP servers and use the provided tools to traverse the knowledge graph and perform complex reasoning. The tests will validate both the MCP interfaces that LLMs use AND the underlying cognitive algorithms.

## System Architecture - Corrected Understanding

### MCP Server Architecture
LLMKG provides two MCP servers that LLMs can connect to:

1. **LLMFriendlyMCPServer** (`src/mcp/llm_friendly_server/`)
   - Simplified interface for LLMs to interact with the knowledge graph
   - Tools: `find_facts`, `ask_question`, `explore_connections`, `store_fact`, `validate_data`
   - Handles natural language queries and converts them to graph operations

2. **BrainInspiredMCPServer** (`src/mcp/brain_inspired_server.rs`)
   - Advanced cognitive capabilities through `CognitiveOrchestrator`
   - Provides access to all 7 cognitive algorithms
   - Tools: `cognitive_query` with pattern selection

### Cognitive Algorithm Integration
- The cognitive algorithms operate on graph structures, NOT on natural language
- LLMs send queries through MCP tools, which parse and convert them to graph queries
- The `CognitiveOrchestrator` selects and executes appropriate algorithms
- Results are formatted back into LLM-friendly responses

### Learning Systems Integration
- **HebbianLearningEngine**: Strengthens connections based on usage patterns
- **AdaptiveLearningSystem**: Optimizes algorithm parameters over time
- **GraphOptimizationAgent**: Identifies and implements structural improvements
- These systems learn from query patterns, not individual queries

## The 7 Cognitive Algorithms - Testing Requirements

### 1. **Convergent Thinking** (`src/cognitive/convergent.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "convergent"`
- **Test Requirements**:
  - Verify beam search with varying depths (1-20 levels)
  - Test activation threshold impacts (0.1 to 0.9)
  - Validate single best answer selection
  - Performance with dense vs sparse graphs

### 2. **Divergent Thinking** (`src/cognitive/divergent.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "divergent"`
- **Test Requirements**:
  - Test exploration breadth (10 to 1000+ nodes)
  - Validate creativity scoring algorithms
  - Test novelty weight impacts
  - Verify diverse result generation

### 3. **Critical Thinking** (`src/cognitive/critical.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "critical"`
- **Test Requirements**:
  - Test contradiction detection accuracy
  - Validate source credibility assessment
  - Test resolution strategies
  - Verify temporal contradiction handling

### 4. **Systems Thinking** (`src/cognitive/systems.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "systems"`
- **Test Requirements**:
  - Test deep hierarchy traversal (up to 20 levels)
  - Validate inheritance rules
  - Test exception handling
  - Verify multiple inheritance resolution

### 5. **Lateral Thinking** (`src/cognitive/lateral.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "lateral"`
- **Test Requirements**:
  - Test bridge finding algorithms (BFS, random walk, semantic)
  - Validate cross-domain connections
  - Test max bridge length constraints
  - Verify path uniqueness

### 6. **Abstract Thinking** (`src/cognitive/abstract_pattern.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "abstract"`
- **Test Requirements**:
  - Test pattern detection across types (structural, temporal, semantic, usage)
  - Validate abstraction quality
  - Test refactoring suggestions
  - Verify meta-pattern recognition

### 7. **Adaptive Thinking** (`src/cognitive/adaptive.rs`)
- **MCP Access**: Via `cognitive_query` with `pattern: "adaptive"` or `strategy: "automatic"`
- **Test Requirements**:
  - Test strategy selection logic
  - Validate ensemble coordination
  - Test pattern switching
  - Verify performance improvement over time

## Test Data Generation Strategy with CognitiveTestDataSynthesizer

### Integration with Existing Synthesizer
```rust
use llmkg::tests::cognitive_test_data_synthesizer::CognitiveTestDataSynthesizer;

pub async fn generate_test_data() -> Result<TestDataset> {
    let mut synthesizer = CognitiveTestDataSynthesizer::new().await?;
    
    // Phase 1: Use existing comprehensive knowledge base
    synthesizer.synthesize_comprehensive_knowledge_base().await?;
    
    // Phase 2: Scale up to meet requirements (300k nodes, 500k relationships)
    synthesizer.scale_to_production_size().await?;
    
    // Phase 3: Add temporal and federation layers
    synthesizer.add_temporal_layers().await?;
    synthesizer.create_federated_databases().await?;
    
    TestDataset {
        graph: synthesizer.graph,
        entity_registry: synthesizer.entity_registry,
        nodes: 300_000+,
        relationships: 500_000+,
        databases: 5, // Multi-layer federation
        temporal_range: 10 years
    }
}
```

### Scaling Strategy for 300k Nodes / 500k Relationships

1. **Domain Expansion** (Current: ~1000 nodes â†’ Target: 300k nodes)
   ```rust
   impl CognitiveTestDataSynthesizer {
       pub async fn scale_to_production_size(&mut self) -> Result<()> {
           // Expand each domain from ~200 to ~50k nodes
           self.expand_biological_taxonomy(50_000).await?;
           self.expand_technology_domain(50_000).await?;
           self.expand_art_culture_domain(50_000).await?;
           self.expand_business_domain(50_000).await?;
           self.expand_geographic_domain(50_000).await?;
           self.expand_medical_domain(50_000).await?;
           
           // Add cross-domain relationships
           self.create_interdomain_connections(100_000).await?;
           
           Ok(())
       }
   }
   ```

2. **Temporal Layer Generation**
   ```rust
   pub async fn add_temporal_layers(&mut self) -> Result<()> {
       // Create temporal versions of entities
       for (name, key) in &self.entity_registry {
           // Add historical versions (10 year range)
           for year in 2014..2024 {
               let temporal_entity = self.create_temporal_version(
                   key, 
                   Utc.ymd(year, 1, 1).and_hms(0, 0, 0)
               ).await?;
           }
       }
       
       // Add temporal relationships
       self.create_temporal_relationships().await?;
   }
   ```

3. **Federation Structure**
   ```rust
   pub async fn create_federated_databases(&mut self) -> Result<()> {
       // Layer 1: Core ontology (stable)
       let ontology_db = self.create_database_layer("ontology", 0.01).await?;
       
       // Layer 2: Instance data (frequent updates)  
       let instance_db = self.create_database_layer("instances", 0.5).await?;
       
       // Layer 3: Temporal snapshots
       let temporal_db = self.create_database_layer("temporal", 0.2).await?;
       
       // Layer 4: User annotations
       let annotation_db = self.create_database_layer("annotations", 0.8).await?;
       
       // Layer 5: Learned patterns
       let learned_db = self.create_database_layer("learned", 0.3).await?;
   }
   ```

## MCP Interface Testing Strategy

### 1. MCP Tool Testing Structure
```rust
#[cfg(test)]
mod mcp_interface_tests {
    use llmkg::mcp::llm_friendly_server::LLMFriendlyMCPServer;
    use llmkg::mcp::brain_inspired_server::BrainInspiredMCPServer;
    
    #[tokio::test]
    async fn test_mcp_find_facts() {
        let server = setup_test_server().await;
        
        // Test natural language to graph query conversion
        let params = json!({
            "subject": "artificial intelligence",
            "predicate": "is_a",
            "limit": 10
        });
        
        let result = server.handle_tool_call("find_facts", params).await;
        assert!(result.is_ok());
        validate_fact_format(&result);
    }
    
    #[tokio::test]
    async fn test_mcp_cognitive_query() {
        let server = setup_brain_server().await;
        
        // Test cognitive pattern invocation
        let params = json!({
            "query": "What is the fastest path from AI to cooking?",
            "pattern": "lateral",
            "max_bridges": 5
        });
        
        let result = server.handle_tool_call("cognitive_query", params).await;
        assert!(result.is_ok());
        validate_lateral_paths(&result);
    }
}
```

### 2. Query Translation Layer Testing
```rust
#[cfg(test)]
mod query_translation_tests {
    #[test]
    fn test_natural_language_to_graph_query() {
        let nl_query = "What are all the types of neural networks?";
        let graph_query = parse_to_graph_query(nl_query);
        
        assert_eq!(graph_query.pattern, QueryPattern::Hierarchical);
        assert_eq!(graph_query.root_entity, Some("neural_networks"));
        assert_eq!(graph_query.relationship_type, Some("is_a"));
    }
    
    #[test]
    fn test_entity_extraction() {
        let query = "How is quantum computing related to cryptography?";
        let entities = extract_entities(query);
        
        assert!(entities.contains("quantum_computing"));
        assert!(entities.contains("cryptography"));
    }
}
```

## Test Suite Structure - 56 Tests Total

### A. MCP Interface Tests (28 tests - 4 per algorithm)

Each algorithm needs 4 MCP interface tests:
1. **Basic MCP Invocation**: Verify tool call with minimal parameters
2. **Complex Query Translation**: Test natural language to graph query conversion
3. **Parameter Validation**: Test boundary conditions and invalid inputs
4. **Result Formatting**: Verify LLM-friendly response structure

### B. Algorithm Integration Tests (28 tests - 4 per algorithm)

Each algorithm needs 4 integration tests:
1. **Graph Scale Test**: Performance with 300k+ nodes
2. **Temporal Feature Test**: Bi-temporal queries and versioning
3. **Federation Test**: Multi-database query coordination
4. **Learning Integration Test**: Interaction with learning systems

## Detailed Test Specifications

### Convergent Thinking Tests

#### MCP Interface Tests
1. **Basic Convergent MCP Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_basic_mcp() {
       let server = setup_mcp_server().await;
       let query = "What is the capital of France?";
       
       let result = server.cognitive_query(query, "convergent").await;
       assert_single_answer(&result, "Paris");
   }
   ```

2. **Complex Query Translation Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_query_translation() {
       let complex_query = "Find the specific enzyme that breaks down lactose in mammals";
       let translated = translate_to_graph_query(complex_query);
       
       assert_eq!(translated.depth_limit, Some(10));
       assert_eq!(translated.beam_width, Some(5));
   }
   ```

3. **Parameter Validation Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_parameter_boundaries() {
       // Test invalid activation threshold
       let result = cognitive_query(query, json!({
           "activation_threshold": 1.5  // Invalid: > 1.0
       }));
       assert!(result.is_err());
   }
   ```

4. **Result Format Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_llm_format() {
       let result = cognitive_query(query, "convergent").await;
       
       assert!(result.contains_key("answer"));
       assert!(result.contains_key("confidence"));
       assert!(result.contains_key("reasoning_path"));
   }
   ```

#### Algorithm Integration Tests
1. **Scale Test with 300k Nodes**
   ```rust
   #[tokio::test]
   async fn test_convergent_scale() {
       let graph = create_300k_node_graph().await;
       let start = Instant::now();
       
       let result = convergent_search(graph, "CEO of largest tech company").await;
       
       assert!(start.elapsed() < Duration::from_millis(100));
       assert_eq!(result.answer, expected_ceo());
   }
   ```

2. **Temporal Convergent Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_temporal() {
       let query = "Who was the president in 2020?";
       let temporal_context = TemporalContext {
           valid_time: Utc.ymd(2020, 6, 1),
           as_of_time: Utc::now(),
       };
       
       let result = temporal_convergent_query(query, temporal_context).await;
       assert_temporal_accuracy(&result);
   }
   ```

3. **Federation Convergent Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_federation() {
       let federated_graph = setup_5_layer_federation().await;
       
       // Query that requires data from multiple layers
       let result = federated_convergent_query(
           "Current market cap of company X with historical context"
       ).await;
       
       assert!(result.sources.len() >= 3); // Multiple databases used
   }
   ```

4. **Learning Integration Test**
   ```rust
   #[tokio::test]
   async fn test_convergent_with_learning() {
       let mut system = create_system_with_learning().await;
       
       // Run same query multiple times
       for i in 0..10 {
           let result = system.convergent_query("Complex technical question").await;
           if i > 5 {
               // Performance should improve after learning
               assert!(result.response_time < initial_time * 0.8);
           }
       }
   }
   ```

### Divergent Thinking Tests

#### MCP Interface Tests
1. **Basic Divergent MCP Test**
   ```rust
   #[tokio::test]
   async fn test_divergent_basic_mcp() {
       let result = mcp_cognitive_query("What can I make with eggs?", "divergent").await;
       
       assert!(result.suggestions.len() >= 20);
       assert_diversity(&result.suggestions, 0.7); // High diversity score
   }
   ```

2. **Exploration Parameters Test**
   ```rust
   #[tokio::test]
   async fn test_divergent_exploration_control() {
       let params = json!({
           "exploration_breadth": 1000,
           "creativity_threshold": 0.8,
           "include_unlikely": true
       });
       
       let result = cognitive_query_with_params(query, "divergent", params).await;
       assert!(result.suggestions.len() >= 100);
   }
   ```

(Continue pattern for all 7 algorithms...)

### Temporal Testing Specifications

```rust
#[cfg(test)]
mod temporal_tests {
    use chrono::{Utc, TimeZone};
    
    #[tokio::test]
    async fn test_bitemporal_query() {
        let graph = create_temporal_graph().await;
        
        // Query: "What was known about COVID-19 in March 2020 vs March 2021"
        let march_2020 = Utc.ymd(2020, 3, 15);
        let march_2021 = Utc.ymd(2021, 3, 15);
        
        let result_2020 = temporal_query(graph, "COVID-19 transmission", march_2020).await;
        let result_2021 = temporal_query(graph, "COVID-19 transmission", march_2021).await;
        
        assert_ne!(result_2020.facts, result_2021.facts);
        assert!(result_2021.facts.len() > result_2020.facts.len());
    }
    
    #[tokio::test]
    async fn test_temporal_contradiction_resolution() {
        // Facts that were true at different times
        let facts = vec![
            ("Pluto", "is_a", "planet", Utc.ymd(1950, 1, 1)),
            ("Pluto", "is_a", "dwarf_planet", Utc.ymd(2006, 8, 24)),
        ];
        
        let result = critical_temporal_analysis("Is Pluto a planet?", Utc::now()).await;
        assert!(result.contains("reclassified"));
    }
}
```

### Federation Testing Specifications

```rust
#[cfg(test)]
mod federation_tests {
    #[tokio::test]
    async fn test_multi_database_coordination() {
        let federation = setup_federation(vec![
            DatabaseLayer::Ontology,
            DatabaseLayer::Instances,
            DatabaseLayer::Temporal,
            DatabaseLayer::Annotations,
            DatabaseLayer::Learned,
        ]).await;
        
        // Query requiring coordination across layers
        let result = federated_query(
            "Show me the evolution of AI definitions with community annotations"
        ).await;
        
        assert_eq!(result.databases_queried.len(), 4);
        assert!(result.merge_strategy == MergeStrategy::Temporal);
    }
    
    #[tokio::test]
    async fn test_federation_consistency() {
        let federation = create_test_federation().await;
        
        // Insert fact in one database
        federation.layer(0).insert_fact("AI", "invented_by", "Turing").await;
        
        // Verify eventually consistent across federation
        tokio::time::sleep(Duration::from_millis(100)).await;
        
        for layer in 1..5 {
            let result = federation.layer(layer).query("AI", "invented_by").await;
            assert!(result.contains("Turing"));
        }
    }
}
```

### Concurrency Testing Specifications

```rust
#[cfg(test)]
mod concurrency_tests {
    use tokio::sync::Barrier;
    use std::sync::Arc;
    
    #[tokio::test]
    async fn test_parallel_mcp_queries() {
        let server = Arc::new(setup_mcp_server().await);
        let barrier = Arc::new(Barrier::new(100));
        
        let mut handles = vec![];
        
        for i in 0..100 {
            let server_clone = server.clone();
            let barrier_clone = barrier.clone();
            
            let handle = tokio::spawn(async move {
                barrier_clone.wait().await;
                
                let result = server_clone.cognitive_query(
                    format!("Query {}", i),
                    "adaptive"
                ).await;
                
                assert!(result.is_ok());
            });
            
            handles.push(handle);
        }
        
        for handle in handles {
            handle.await.unwrap();
        }
    }
    
    #[tokio::test]
    async fn test_activation_engine_thread_safety() {
        let graph = create_test_graph().await;
        let engine = Arc::new(ActivationEngine::new(graph));
        
        // Concurrent activation propagation
        let handles: Vec<_> = (0..50).map(|i| {
            let engine_clone = engine.clone();
            tokio::spawn(async move {
                engine_clone.propagate_activation(
                    format!("node_{}", i),
                    0.5
                ).await
            })
        }).collect();
        
        for handle in handles {
            assert!(handle.await.is_ok());
        }
        
        // Verify no race conditions in activation states
        verify_activation_consistency(&engine).await;
    }
}
```

### Error Scenario Testing

```rust
#[cfg(test)]
mod error_scenario_tests {
    #[tokio::test]
    async fn test_malformed_graph_data_handling() {
        let mut graph = create_test_graph().await;
        
        // Inject malformed data
        graph.inject_cycle("A", "B", "C", "A").await;
        graph.add_invalid_weight("D", "E", 1.5).await; // > 1.0
        
        // Cognitive algorithms should handle gracefully
        let result = systems_thinking_query(graph, "hierarchy of A").await;
        assert!(result.warnings.contains("cycle detected"));
        
        let result2 = convergent_query(graph, "path to E").await;
        assert!(result2.warnings.contains("invalid weight normalized"));
    }
    
    #[tokio::test]
    async fn test_api_timeout_handling() {
        let server = setup_mcp_server_with_timeout(Duration::from_millis(50)).await;
        
        // Query that would take longer than timeout
        let result = server.cognitive_query(
            "Explore all connections in 300k graph",
            "divergent"
        ).await;
        
        assert!(matches!(result, Err(Error::Timeout(_))));
        assert!(server.partial_results_available());
    }
    
    #[tokio::test]
    async fn test_memory_pressure_handling() {
        let config = SystemConfig {
            max_memory_gb: 2.0,
            enable_spilling: true,
        };
        
        let system = create_system_with_config(config).await;
        
        // Load large dataset
        let result = system.load_300k_graph().await;
        assert!(result.is_ok());
        
        // Verify memory-efficient operation
        assert!(system.memory_usage_gb() < 2.0);
        assert!(system.spill_files_created() > 0);
    }
}
```

### Learning System Integration Tests

```rust
#[cfg(test)]
mod learning_integration_tests {
    #[tokio::test]
    async fn test_hebbian_learning_impact() {
        let mut system = create_system_with_hebbian_learning().await;
        
        // Repeatedly query same paths
        for _ in 0..20 {
            system.lateral_query("Einstein", "Rock Music").await;
        }
        
        // Verify connection strengthening
        let weights = system.get_path_weights("Einstein", "Rock Music").await;
        assert!(weights.iter().all(|w| *w > 0.7));
    }
    
    #[tokio::test]
    async fn test_adaptive_parameter_tuning() {
        let mut adaptive_system = AdaptiveLearningSystem::new().await;
        
        // Run queries with feedback
        for i in 0..50 {
            let result = adaptive_system.query_with_parameters(
                "Complex query",
                CognitiveParameters::default()
            ).await;
            
            let feedback = if result.quality > 0.8 { 
                Feedback::Positive 
            } else { 
                Feedback::Negative 
            };
            
            adaptive_system.update(feedback).await;
        }
        
        // Parameters should have adapted
        let final_params = adaptive_system.get_parameters();
        assert_ne!(final_params, CognitiveParameters::default());
        assert!(adaptive_system.performance_improved());
    }
}
```

## DeepSeek Integration Tests

Since the system is designed for LLMs to connect via MCP, DeepSeek tests will simulate an LLM using the MCP interface:

```rust
#[cfg(test)]
mod deepseek_integration_tests {
    use deepseek_client::DeepSeekClient;
    
    #[tokio::test] 
    async fn test_deepseek_mcp_integration() {
        let mcp_server = start_mcp_server().await;
        let deepseek = DeepSeekClient::new(env::var("DEEPSEEK_API_KEY")?);
        
        // Simulate DeepSeek connecting to MCP
        let connection = deepseek.connect_to_mcp(mcp_server.url()).await?;
        
        // DeepSeek formulates natural language query
        let llm_query = deepseek.generate_query(
            "I need to find connections between quantum computing and cooking"
        ).await?;
        
        // Query goes through MCP interface
        let mcp_result = connection.call_tool("cognitive_query", json!({
            "query": llm_query,
            "pattern": "lateral",
            "params": {
                "max_bridges": 5,
                "creativity_boost": 0.8
            }
        })).await?;
        
        // DeepSeek processes graph results
        let llm_response = deepseek.interpret_graph_results(mcp_result).await?;
        
        assert!(llm_response.contains("molecular gastronomy"));
        assert!(llm_response.contains("precision"));
    }
    
    #[tokio::test]
    async fn test_deepseek_adaptive_reasoning() {
        // Test DeepSeek's ability to use adaptive reasoning
        let queries = vec![
            "What is quantum computing?", // Convergent
            "Creative uses for quantum computing", // Divergent  
            "Quantum computing vs classical computing", // Critical
            "How quantum computing fits in tech ecosystem", // Systems
        ];
        
        for query in queries {
            let result = deepseek_via_mcp(query, "adaptive").await;
            
            // Verify appropriate pattern was selected
            assert!(result.metadata.pattern_used.is_appropriate_for(query));
        }
    }
}
```

## Performance Requirements

1. **Query Response Times**:
   - Convergent: < 100ms for focused search
   - Divergent: < 500ms for 1000-node exploration
   - Critical: < 200ms for contradiction detection
   - Systems: < 150ms for 15-level hierarchy
   - Lateral: < 300ms for 5-bridge path
   - Abstract: < 400ms for pattern analysis
   - Adaptive: < 50ms for strategy selection + algorithm time

2. **Memory Constraints**:
   - Full 300k graph loaded: < 4GB RAM
   - Activation propagation: < 500MB additional
   - Concurrent queries: < 100MB per query

3. **Concurrency**:
   - Support 100+ simultaneous MCP connections
   - Thread-safe activation propagation
   - Lock-free read operations where possible

## Deliverables

### 1. Test Implementation Structure
```
tests/
â”œâ”€â”€ mcp_interface_tests/
â”‚   â”œâ”€â”€ llm_friendly_server_tests.rs
â”‚   â”œâ”€â”€ brain_inspired_server_tests.rs
â”‚   â”œâ”€â”€ query_translation_tests.rs
â”‚   â””â”€â”€ tool_validation_tests.rs
â”œâ”€â”€ cognitive_algorithm_tests/
â”‚   â”œâ”€â”€ convergent_tests.rs
â”‚   â”œâ”€â”€ divergent_tests.rs
â”‚   â”œâ”€â”€ critical_tests.rs
â”‚   â”œâ”€â”€ systems_tests.rs
â”‚   â”œâ”€â”€ lateral_tests.rs
â”‚   â”œâ”€â”€ abstract_tests.rs
â”‚   â””â”€â”€ adaptive_tests.rs
â”œâ”€â”€ integration_tests/
â”‚   â”œâ”€â”€ temporal_tests.rs
â”‚   â”œâ”€â”€ federation_tests.rs
â”‚   â”œâ”€â”€ learning_integration_tests.rs
â”‚   â””â”€â”€ scale_tests.rs
â”œâ”€â”€ concurrency_tests/
â”‚   â”œâ”€â”€ parallel_query_tests.rs
â”‚   â”œâ”€â”€ thread_safety_tests.rs
â”‚   â””â”€â”€ activation_engine_tests.rs
â”œâ”€â”€ error_scenario_tests/
â”‚   â”œâ”€â”€ malformed_data_tests.rs
â”‚   â”œâ”€â”€ timeout_tests.rs
â”‚   â””â”€â”€ recovery_tests.rs
â”œâ”€â”€ deepseek_integration/
â”‚   â”œâ”€â”€ mcp_connection_tests.rs
â”‚   â”œâ”€â”€ natural_language_tests.rs
â”‚   â””â”€â”€ adaptive_reasoning_tests.rs
â””â”€â”€ test_data/
    â”œâ”€â”€ scaled_synthesizer.rs
    â”œâ”€â”€ temporal_generator.rs
    â””â”€â”€ federation_builder.rs
```

### 2. Test Data Generation Pipeline
```rust
pub struct ScaledTestDataGenerator {
    synthesizer: CognitiveTestDataSynthesizer,
    target_nodes: usize,        // 300,000
    target_relationships: usize, // 500,000
    domains: Vec<Domain>,
    temporal_range: Duration,
    federation_layers: usize,
}

impl ScaledTestDataGenerator {
    pub async fn generate_full_test_environment(&mut self) -> Result<TestEnvironment> {
        // Step 1: Generate base data with synthesizer
        self.synthesizer.synthesize_comprehensive_knowledge_base().await?;
        
        // Step 2: Scale to production size
        self.scale_domains_proportionally().await?;
        
        // Step 3: Add temporal dimensions
        self.generate_temporal_versions().await?;
        
        // Step 4: Create federation structure  
        self.setup_multi_layer_federation().await?;
        
        // Step 5: Inject test scenarios
        self.add_contradictions_for_critical_thinking().await?;
        self.add_patterns_for_abstract_thinking().await?;
        self.add_bridges_for_lateral_thinking().await?;
        
        Ok(TestEnvironment {
            graph: self.synthesizer.graph,
            stats: self.collect_statistics(),
        })
    }
}
```

### 3. MCP Testing Framework
```rust
pub trait MCPTestFramework {
    async fn setup_server(&self) -> Result<MCPServer>;
    async fn validate_tool_response(&self, tool: &str, response: Value) -> Result<()>;
    async fn simulate_llm_connection(&self) -> Result<MCPConnection>;
    async fn measure_performance(&self, operation: MCPOperation) -> Result<Metrics>;
}
```

### 4. Continuous Integration Configuration
```yaml
# .github/workflows/cognitive_tests.yml
name: LLMKG Cognitive Algorithm Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Setup Test Data
      run: |
        cargo run --bin generate_test_data -- \
          --nodes 300000 \
          --relationships 500000 \
          --output ./test_data
    
    - name: Run MCP Interface Tests
      run: cargo test --package llmkg --test mcp_interface_tests
      
    - name: Run Cognitive Algorithm Tests  
      run: cargo test --package llmkg --test cognitive_algorithm_tests
      
    - name: Run Integration Tests
      run: cargo test --package llmkg --test integration_tests
      
    - name: Run Concurrency Tests
      run: cargo test --package llmkg --test concurrency_tests -- --test-threads=1
      
    - name: Run DeepSeek Integration Tests
      env:
        DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
      run: cargo test --package llmkg --test deepseek_integration
```

## Success Criteria

1. **MCP Interface Validation**:
   - All MCP tools properly convert natural language to graph queries
   - Response formats are LLM-friendly (JSON with clear structure)
   - Error messages are informative for LLM interpretation

2. **Algorithm Performance**:
   - All algorithms meet performance targets with 300k nodes
   - Memory usage stays within 4GB limit
   - Concurrent query handling without degradation

3. **Integration Completeness**:
   - Temporal features work across all algorithms
   - Federation queries coordinate properly
   - Learning systems improve performance over time

4. **LLM Usability**:
   - DeepSeek can successfully use all cognitive patterns
   - Natural language queries produce meaningful results
   - System provides human-like reasoning capabilities

This refactored testing strategy correctly positions LLMKG as an MCP server that provides cognitive reasoning tools to LLMs, rather than trying to integrate LLMs into the algorithms themselves. The tests validate both the MCP interfaces that LLMs use and the underlying cognitive algorithms that power the system.